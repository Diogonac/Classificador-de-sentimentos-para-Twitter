{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: _____\n",
    "\n",
    "Nome: Diogo Nobre de Araujo Cintra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange\n",
    "from numpy import percentile\n",
    "import numpy as np\n",
    "import os\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@Ciencia dos dados***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Correios'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "#### 0 = irrelevante\n",
    "#### 1 = relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREINAMENTO = pd.read_excel('Correios.xlsx',sheet_name = 'Treinamento')\n",
    "TESTE = pd.read_excel('Correios.xlsx',sheet_name = 'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREINAMENTO_RELEVANTE = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==1]\n",
    "TREINAMENTO_IRRELEVANTE = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==0]\n",
    "\n",
    "def clean(text):\n",
    "    punctuation = '[!\\-.:?;#$%&*_1234567890\"]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_relevante = \" \".join(TREINAMENTO_RELEVANTE['Treinamento'])\n",
    "texto_relevante_1 = clean(texto_relevante)\n",
    "texto_relevante_2 = texto_relevante_1.split()\n",
    "texto_relevante_3 = []\n",
    "\n",
    "texto_irrelevante = \" \".join(TREINAMENTO_IRRELEVANTE['Treinamento'])\n",
    "texto_irrelevante_1 = clean(texto_irrelevante)\n",
    "texto_irrelevante_2 = texto_irrelevante_1.split()\n",
    "texto_irrelevante_3 = []\n",
    "\n",
    "treinamento = \" \".join(TREINAMENTO['Treinamento'])\n",
    "treinamento_1 = clean(treinamento)\n",
    "treinamento_2 = treinamento_1.split()\n",
    "treinamento_3 = []\n",
    "\n",
    "for e in range(len(texto_relevante_2)-1):\n",
    "    if texto_relevante_2[e] != 'rt' and texto_relevante_2[e][0] != '@':     \n",
    "        texto_relevante_3.append(texto_relevante_2[e])    \n",
    "        \n",
    "for e in range(len(texto_irrelevante_2)-1):\n",
    "    if texto_irrelevante_2[e] != 'rt' and texto_irrelevante_2[e][0] != '@':     \n",
    "        texto_irrelevante_3.append(texto_irrelevante_2[e]) \n",
    "        \n",
    "for e in range(len(treinamento_2)-1):\n",
    "    if treinamento_2[e] != 'rt' and treinamento_2[e][0] != '@':     \n",
    "        treinamento_3.append(treinamento_2[e])\n",
    "        \n",
    "texto_relevante_4 = pd.Series(texto_relevante_3)\n",
    "texto_irrelevante_4 = pd.Series(texto_irrelevante_3)\n",
    "treinamento_4 = pd.Series(treinamento_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade do tweet ser relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4027777777777778"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_amostral = len(treinamento_4)-1\n",
    "total_relevante = len(texto_relevante_4)\n",
    "prob_relevante = total_relevante/total_amostral\n",
    "prob_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade do tweet ser relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5972222222222222"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_amostral = len(treinamento_4)-1\n",
    "total_irrelevante = len(texto_irrelevante_4)\n",
    "prob_irrelevante = total_irrelevante/total_amostral\n",
    "prob_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#contador das palavras\n",
    "def conta_palavra(texto, dic):\n",
    "    texto_sem_pontuacao = clean(texto)\n",
    "    palavras_do_texto = texto_sem_pontuacao.split()\n",
    "    palavras=dic\n",
    "    for p in palavras_do_texto:\n",
    "        if p in palavras:\n",
    "            palavras[p]+=1\n",
    "        else:\n",
    "            palavras[p]=1\n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correios        0.021303\n",
       "de              0.018936\n",
       "o               0.016412\n",
       "que             0.016254\n",
       "a               0.013255\n",
       "os              0.010415\n",
       "dos             0.009153\n",
       "e               0.007732\n",
       "//t             0.007101\n",
       "https           0.007101\n",
       "uma             0.006943\n",
       "em              0.006786\n",
       "do              0.006154\n",
       "√©               0.005997\n",
       "no              0.005839\n",
       "na              0.005365\n",
       "n√£o             0.005208\n",
       "correios,       0.004103\n",
       "da              0.004103\n",
       "se              0.003945\n",
       "governo         0.003629\n",
       "transformar     0.003472\n",
       "ao              0.003472\n",
       "sobre           0.003472\n",
       "eu              0.003314\n",
       "com             0.003156\n",
       "privatiza√ß√£o    0.003156\n",
       "para            0.003156\n",
       "amazon          0.002998\n",
       "por             0.002840\n",
       "                  ...   \n",
       "direitos,       0.000158\n",
       "s               0.000158\n",
       "deixaria        0.000158\n",
       "enviava         0.000158\n",
       "seja            0.000158\n",
       "vendia          0.000158\n",
       "amazon‚Äù         0.000158\n",
       "desgra√ßa        0.000158\n",
       "co/buhjm        0.000158\n",
       "novo            0.000158\n",
       "envelope        0.000158\n",
       "somos           0.000158\n",
       "disser          0.000158\n",
       "perda           0.000158\n",
       "üî•hot            0.000158\n",
       "zona            0.000158\n",
       "jm              0.000158\n",
       "somente         0.000158\n",
       "amaz√¥nia,       0.000158\n",
       "acionista       0.000158\n",
       "formada         0.000158\n",
       "madrugada       0.000158\n",
       "filho           0.000158\n",
       "pa√≠s            0.000158\n",
       "encomendas      0.000158\n",
       "substitu√≠ram    0.000158\n",
       "quentinho       0.000158\n",
       "dirigir         0.000158\n",
       "sinceros,       0.000158\n",
       "gasolina        0.000158\n",
       "Length: 1296, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#associa um valor de probabilidade\n",
    "#probrev={}\n",
    "#formato {palavra:valor}\n",
    "#probnorev={}\n",
    "#formato {palavra:valor}\n",
    "\n",
    "total_amostral = len(treinamento_4)\n",
    "total_relevante = texto_relevante_4.value_counts()\n",
    "total_irrelevante = texto_irrelevante_4.value_counts()\n",
    "\n",
    "#Probabilidade da palavra ser relevante\n",
    "prob_relevante_palavra = total_relevante/total_amostral\n",
    "prob_relevante_palavra\n",
    "\n",
    "#Probabilidade da palavra ser irrelevante\n",
    "prob_irrelevante_palavra = total_irrelevante/total_amostral\n",
    "prob_irrelevante_palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoth = 1/1000000 #√© uma estimativa e deve mudar\n",
    "\n",
    "# defini probabilidade de ser relevante:\n",
    "def relevante(tweet):\n",
    "    t = clean(tweet)\n",
    "    t = t.split()\n",
    "    txt = []\n",
    "    for e in range(len(t)-1):\n",
    "        if t[e] != 'rt' and t[e][0] != '@':     \n",
    "            txt.append(t[e])\n",
    "    prob = 1\n",
    "    for p in txt:\n",
    "        if p in prob_relevante_palavra:\n",
    "            prob = prob*(prob_relevante_palavra[p]+smoth)\n",
    "        else:\n",
    "            prob = prob*(smoth)\n",
    "    prob = prob * prob_relevante\n",
    "    return prob\n",
    "# defini probabilidade de ser irrelevante:\n",
    "\n",
    "def irrelevante(tweet):\n",
    "    t = clean(tweet)\n",
    "    t = t.split()\n",
    "    txt = []\n",
    "    for e in range(len(t)-1):\n",
    "        if t[e] != 'rt' and t[e][0] != '@':     \n",
    "            txt.append(t[e])\n",
    "    prob = 1\n",
    "    for p in txt:\n",
    "        if p in prob_irrelevante_palavra:\n",
    "            prob = prob*(prob_irrelevante_palavra[p]+smoth)\n",
    "        else:\n",
    "            prob = prob*(smoth)\n",
    "    prob = prob * prob_irrelevante\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara (tweet):\n",
    "    r = relevante(tweet)\n",
    "    nor = irrelevante(tweet)\n",
    "    return r>nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a probabilidade de ser relevante √© 0.235\n",
      "a probabilidade de n√£o ser relevante √© 0.765\n",
      "poucos relevantes 0.5834482758620689 vezes o esperado\n"
     ]
    }
   ],
   "source": [
    "rev = 0\n",
    "norev = 0\n",
    "for txt in TESTE[\"Teste\"]:\n",
    "    if compara (txt):\n",
    "        rev +=1\n",
    "    else:\n",
    "        norev+=1\n",
    "print (\"a probabilidade de ser relevante √© {}\".format(rev/TESTE[\"Teste\"].size))\n",
    "print (\"a probabilidade de n√£o ser relevante √© {}\".format(norev/TESTE[\"Teste\"].size))\n",
    "if rev/(TESTE[\"Teste\"].size) < 0.9*prob_relevante:\n",
    "    print (\"poucos relevantes {} vezes o esperado\".format (rev/TESTE[\"Teste\"].size/prob_relevante))\n",
    "elif rev/(TESTE[\"Teste\"].size) > 1.1*prob_relevante:\n",
    "    print (\"muitos relevantes {} vezes o esperado\" .format (rev/TESTE[\"Teste\"].size/prob_relevante))\n",
    "else:\n",
    "    print (\"ok: {} veze o esperado\".format (rev/TESTE[\"Teste\"].size/prob_relevante))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
