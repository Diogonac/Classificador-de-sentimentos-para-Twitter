{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: _____\n",
    "\n",
    "Nome: Diogo Nobre de Araujo Cintra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-797685fe92f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2305\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2306\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2307\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2308\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<C:\\Users\\diogo\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\decorator.py:decorator-gen-109>\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\IPython\\core\\magics\\pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   3370\u001b[0m         \"\"\"\n\u001b[0;32m   3371\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3372\u001b[1;33m         \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3374\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[1;34m(gui, gui_select)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \"\"\"\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange\n",
    "from numpy import percentile\n",
    "import numpy as np\n",
    "import os\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@Ciencia dos dados***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Correios'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "#### 0 = irrelevante\n",
    "#### 1 = relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREINAMENTO = pd.read_excel('Correios.xlsx',sheet_name = 'Treinamento')\n",
    "TESTE = pd.read_excel('Correios.xlsx',sheet_name = 'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREINAMENTO_RELEVANTE = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==1]\n",
    "TREINAMENTO_IRRELEVANTE = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==0]\n",
    "\n",
    "def clean(text):\n",
    "    punctuation = '[!\\-.:?;#$%&*_1234567890\"]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_relevante = \" \".join(TREINAMENTO_RELEVANTE['Treinamento'])\n",
    "texto_relevante_1 = clean(texto_relevante)\n",
    "texto_relevante_2 = texto_relevante_1.split()\n",
    "texto_relevante_3 = []\n",
    "\n",
    "texto_irrelevante = \" \".join(TREINAMENTO_IRRELEVANTE['Treinamento'])\n",
    "texto_irrelevante_1 = clean(texto_irrelevante)\n",
    "texto_irrelevante_2 = texto_irrelevante_1.split()\n",
    "texto_irrelevante_3 = []\n",
    "\n",
    "treinamento = \" \".join(TREINAMENTO['Treinamento'])\n",
    "treinamento_1 = clean(treinamento)\n",
    "treinamento_2 = treinamento_1.split()\n",
    "treinamento_3 = []\n",
    "\n",
    "for e in range(len(texto_relevante_2)-1):\n",
    "    if texto_relevante_2[e] != 'rt' and texto_relevante_2[e][0] != '@':     \n",
    "        texto_relevante_3.append(texto_relevante_2[e])    \n",
    "        \n",
    "for e in range(len(texto_irrelevante_2)-1):\n",
    "    if texto_irrelevante_2[e] != 'rt' and texto_irrelevante_2[e][0] != '@':     \n",
    "        texto_irrelevante_3.append(texto_irrelevante_2[e]) \n",
    "        \n",
    "for e in range(len(treinamento_2)-1):\n",
    "    if treinamento_2[e] != 'rt' and treinamento_2[e][0] != '@':     \n",
    "        treinamento_3.append(treinamento_2[e])\n",
    "        \n",
    "texto_relevante_4 = pd.Series(texto_relevante_3)\n",
    "texto_irrelevante_4 = pd.Series(texto_irrelevante_3)\n",
    "treinamento_4 = pd.Series(treinamento_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de uma palavra ser relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4027777777777778"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total_amostral = treinamento_4.value_counts()\n",
    "#total_relevante = texto_relevante_4.value_counts()\n",
    "\n",
    "TREINAMENTO.Classificacao.value_counts()\n",
    "prev = 120/300 #probabilidade de ser relevante geral\n",
    "\n",
    "total_amostral = len(treinamento_4)-1\n",
    "total_relevante = len(texto_relevante_4)\n",
    "prob_relevante = total_relevante/total_amostral\n",
    "prob_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de uma palavra ser irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5972222222222222"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total_amostral = treinamento_4.value_counts()\n",
    "#total_relevante = texto_relevante_4.value_counts()\n",
    "\n",
    "TREINAMENTO.Classificacao.value_counts()\n",
    "prev = 180/300 #probabilidade de ser relevante geral\n",
    "\n",
    "total_amostral = len(treinamento_4)-1\n",
    "total_irrelevante = len(texto_irrelevante_4)\n",
    "prob_irrelevante = total_irrelevante/total_amostral\n",
    "prob_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#probabilidade de ser relevante\n",
    "TREINAMENTO.Classificacao.value_counts()\n",
    "prev = 120/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidade de não ser relevante\n",
    "pnorev = 180/300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contador das palavras\n",
    "def conta_palavra(texto, dic):\n",
    "    texto_sem_pontuacao = clean(texto)\n",
    "    palavras_do_texto = texto_sem_pontuacao.split()\n",
    "    palavras=dic\n",
    "    for p in palavras_do_texto:\n",
    "        if p in palavras:\n",
    "            palavras[p]+=1\n",
    "        else:\n",
    "            palavras[p]=1\n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rt': 69,\n",
       " '@arthurmoledoval': 17,\n",
       " 'o': 104,\n",
       " 'governo': 23,\n",
       " 'recomendou': 15,\n",
       " 'ao': 22,\n",
       " 'bndes': 16,\n",
       " 'que': 103,\n",
       " 'os': 66,\n",
       " 'estudos': 15,\n",
       " 'sobre': 22,\n",
       " 'uma': 44,\n",
       " 'eventual': 15,\n",
       " 'privatização': 20,\n",
       " 'dos': 58,\n",
       " 'correios': 135,\n",
       " 'fiquem': 15,\n",
       " 'prontos': 15,\n",
       " 'em': 43,\n",
       " 'até': 16,\n",
       " 'mese…': 15,\n",
       " '@casonatogabriel': 11,\n",
       " 'a': 84,\n",
       " 'amazon,': 14,\n",
       " 'empresa': 16,\n",
       " 'na': 34,\n",
       " 'qual': 12,\n",
       " 'queremos': 11,\n",
       " 'transformar': 22,\n",
       " 'correios,': 26,\n",
       " 'lança': 11,\n",
       " 'hoje': 15,\n",
       " 'no': 37,\n",
       " 'brasil': 15,\n",
       " 'programa': 11,\n",
       " 'prime,': 11,\n",
       " 'dá': 11,\n",
       " 'aos': 15,\n",
       " 'seus': 12,\n",
       " 'ass…': 11,\n",
       " '@willianlofy': 1,\n",
       " 'usam': 2,\n",
       " 'quem': 3,\n",
       " 'quer,': 1,\n",
       " 'como': 15,\n",
       " '“todos”': 1,\n",
       " 'sabem,': 1,\n",
       " 'monopólio': 4,\n",
       " 'é': 38,\n",
       " 'somente': 1,\n",
       " 'daquelas': 1,\n",
       " 'cartinhas': 1,\n",
       " 'ninguém': 2,\n",
       " 'mais': 16,\n",
       " 'usa': 1,\n",
       " 'pessoa': 3,\n",
       " 'vai': 14,\n",
       " 'dirigir': 1,\n",
       " 'de': 120,\n",
       " 'madrugada': 1,\n",
       " 'achando': 1,\n",
       " 'braian': 1,\n",
       " 'ai': 3,\n",
       " 'dps': 1,\n",
       " 'fica': 2,\n",
       " 'um': 17,\n",
       " 'mês': 2,\n",
       " 'indo': 2,\n",
       " 'caixinha': 2,\n",
       " 'todo': 6,\n",
       " 'dia': 3,\n",
       " 'temendo': 1,\n",
       " 'multa': 1,\n",
       " 'nova': 3,\n",
       " 'tem': 12,\n",
       " 'se': 25,\n",
       " 'fuder': 1,\n",
       " 'msm': 2,\n",
       " 'mas': 12,\n",
       " 'deu': 3,\n",
       " 'tudo': 5,\n",
       " 'certo,': 1,\n",
       " 'não': 33,\n",
       " 'passei': 3,\n",
       " 'acima': 1,\n",
       " 'do': 39,\n",
       " 'limite': 1,\n",
       " '😂😂😂': 2,\n",
       " 'uns': 2,\n",
       " 'males': 1,\n",
       " 'vem': 3,\n",
       " 'pra': 17,\n",
       " 'bem': 8,\n",
       " 'sdd': 1,\n",
       " 'quando': 6,\n",
       " 'tinha': 1,\n",
       " 'aqueles': 3,\n",
       " 'anônimos,': 1,\n",
       " 'eu': 21,\n",
       " 'adorava': 1,\n",
       " 'foi': 8,\n",
       " 'mesmo': 12,\n",
       " 'melhor': 1,\n",
       " 'ano': 1,\n",
       " '@thefaceofnike': 1,\n",
       " 'han,': 1,\n",
       " 'aqui': 5,\n",
       " 'nesse': 2,\n",
       " 'pique,': 1,\n",
       " 'bom': 3,\n",
       " 'vermelha': 1,\n",
       " 'passa': 2,\n",
       " 'caminhão': 1,\n",
       " 'permissão,': 1,\n",
       " 'as': 7,\n",
       " 'carreta': 2,\n",
       " 'bagulho': 1,\n",
       " 'bate': 1,\n",
       " 'escala': 1,\n",
       " 'richter': 1,\n",
       " '@eniberto': 1,\n",
       " 'real': 1,\n",
       " '@rafaiovanovichi': 1,\n",
       " 'ele': 2,\n",
       " 'disse': 1,\n",
       " 'gosta': 1,\n",
       " 'ti': 1,\n",
       " 'quadrilha': 1,\n",
       " 'alvo': 1,\n",
       " 'da': 26,\n",
       " 'pf': 1,\n",
       " 'tocantins': 1,\n",
       " 'vendia': 1,\n",
       " 'moeda': 1,\n",
       " 'falsa': 1,\n",
       " 'nas': 3,\n",
       " 'redes': 1,\n",
       " 'sociais': 1,\n",
       " 'e': 49,\n",
       " 'enviava': 1,\n",
       " 'pelos': 13,\n",
       " 'https': 45,\n",
       " '//t': 45,\n",
       " 'co/hn': 1,\n",
       " 'hxpjwrp': 1,\n",
       " 'polícia': 2,\n",
       " 'procura': 1,\n",
       " 'por': 18,\n",
       " 'homem': 4,\n",
       " 'roubou': 1,\n",
       " 'agência': 5,\n",
       " 'japonvar': 1,\n",
       " 'co/buhjm': 1,\n",
       " 'ysu': 1,\n",
       " '@ph': 3,\n",
       " 'limass': 3,\n",
       " 'pergunta': 1,\n",
       " 'alguém': 2,\n",
       " 'genuinamente': 1,\n",
       " 'opinião': 1,\n",
       " 'formada': 1,\n",
       " 'assunto': 3,\n",
       " 'solução': 1,\n",
       " 'privatizadora': 1,\n",
       " 'conseguiria': 1,\n",
       " 'suprir': 1,\n",
       " 'vácuo': 1,\n",
       " 'serviço': 4,\n",
       " 'cidades': 2,\n",
       " 'menores': 1,\n",
       " 'quais': 4,\n",
       " 'equivalente': 1,\n",
       " 'privado': 1,\n",
       " 'teria': 2,\n",
       " 'lucro': 2,\n",
       " 'compre': 1,\n",
       " 'atacado': 1,\n",
       " 'varejo': 1,\n",
       " 'enviamos': 1,\n",
       " 'para': 20,\n",
       " 'ou': 8,\n",
       " 'transportadora': 1,\n",
       " 'acesse': 1,\n",
       " 'co/a': 2,\n",
       " 'ux': 1,\n",
       " 'wbsxp': 1,\n",
       " 'natuvel': 1,\n",
       " 'produtosnaturais': 1,\n",
       " 'revenda': 1,\n",
       " 'rendaextra': 1,\n",
       " 'emagrecer': 1,\n",
       " 'dieta': 2,\n",
       " 'fitness': 1,\n",
       " 'saude': 1,\n",
       " 'perderpeso': 1,\n",
       " 'queimagordura': 1,\n",
       " 'atacadonaturais': 1,\n",
       " 'secabarriga': 1,\n",
       " 'co/': 5,\n",
       " 'mkup': 1,\n",
       " 'gn': 1,\n",
       " 'j': 1,\n",
       " '@ferraz': 1,\n",
       " 'rodolpho': 1,\n",
       " 'sim,': 7,\n",
       " 'deixou': 2,\n",
       " 'novamente': 1,\n",
       " '@hebertkiss': 4,\n",
       " 'dilma': 10,\n",
       " 'afirmou': 6,\n",
       " 'esse': 12,\n",
       " 'quer': 8,\n",
       " 'numa': 10,\n",
       " 'amazon': 19,\n",
       " 'anta,': 6,\n",
       " 'plano': 10,\n",
       " 'só': 16,\n",
       " 'esquerdopat…': 4,\n",
       " '@tabataamaralsp': 4,\n",
       " 'nem': 3,\n",
       " 'carta': 3,\n",
       " '@ilysimaria': 1,\n",
       " 'oi': 2,\n",
       " 'aceito': 2,\n",
       " 'ganhar': 2,\n",
       " 'dessess': 2,\n",
       " 'co/vut': 2,\n",
       " 'tvd': 2,\n",
       " 'q': 10,\n",
       " '@bdaysbangtan': 3,\n",
       " '☆': 3,\n",
       " 'motivos': 3,\n",
       " 'vocês': 5,\n",
       " 'podem': 4,\n",
       " 'ter': 7,\n",
       " 'recebido': 3,\n",
       " 'card': 4,\n",
       " 'bdays': 3,\n",
       " 'armys': 3,\n",
       " 'ainda': 6,\n",
       " '(thread)': 3,\n",
       " 'você': 9,\n",
       " 'apenas': 5,\n",
       " 'inscreveu': 3,\n",
       " 'e…': 3,\n",
       " 'disser': 1,\n",
       " 'trabalho': 4,\n",
       " 'me': 5,\n",
       " 'deixaria': 1,\n",
       " 'tocar': 1,\n",
       " 'seu': 9,\n",
       " 'pacote': 1,\n",
       " '—': 1,\n",
       " 'skkskssk': 1,\n",
       " 'co/haq': 1,\n",
       " 'qwjlwn': 1,\n",
       " 'carlos': 1,\n",
       " 'vê': 1,\n",
       " 'fala': 1,\n",
       " 'algo': 2,\n",
       " 'todos': 3,\n",
       " 'estão': 3,\n",
       " 'vendo': 1,\n",
       " 'está': 5,\n",
       " 'frente': 2,\n",
       " 'vender': 2,\n",
       " 'estatal': 5,\n",
       " 'deveria': 1,\n",
       " 'ser': 12,\n",
       " 'fechada': 1,\n",
       " 'pela': 2,\n",
       " 'perda': 1,\n",
       " 'sentido': 1,\n",
       " 'existir,': 1,\n",
       " 'haja': 2,\n",
       " 'barganhas,': 1,\n",
       " 'negociatas': 1,\n",
       " 'argentinizacao': 1,\n",
       " 'querem': 4,\n",
       " 'grande': 5,\n",
       " 'amazon”': 1,\n",
       " 'rousseff,': 1,\n",
       " 'ops': 1,\n",
       " 'amazonprime': 1,\n",
       " 'qwh': 1,\n",
       " 'zn': 1,\n",
       " 'renovar': 1,\n",
       " 'passaporte': 1,\n",
       " 'são': 5,\n",
       " 'euros': 1,\n",
       " 'tenho': 5,\n",
       " 'comprar': 3,\n",
       " 'envelope': 1,\n",
       " 'envio': 5,\n",
       " 'inacreditável': 1,\n",
       " '😠': 1,\n",
       " 'faltou': 1,\n",
       " 'nariz': 1,\n",
       " 'palhaço': 1,\n",
       " '🤡': 1,\n",
       " '@dimacgarcia': 1,\n",
       " 'olavotemrazão': 1,\n",
       " 'sempre': 7,\n",
       " 'isso': 8,\n",
       " 'ficam': 1,\n",
       " 'flavio': 1,\n",
       " 'assina': 1,\n",
       " 'cpi': 15,\n",
       " 'lava': 1,\n",
       " 'toga': 1,\n",
       " 'resolvesse': 1,\n",
       " 'lembra': 1,\n",
       " 'será': 1,\n",
       " 'privatizado,': 1,\n",
       " 'tanto': 1,\n",
       " 'roubado': 1,\n",
       " 'povo': 2,\n",
       " 'vive': 1,\n",
       " 'histeria': 1,\n",
       " '@juliannahbatist': 2,\n",
       " 'amazônia': 2,\n",
       " 'queimando,': 2,\n",
       " 'incidentes': 2,\n",
       " 'diplomáticos,': 2,\n",
       " 'subserviência': 2,\n",
       " 'eua,': 2,\n",
       " 'índices': 2,\n",
       " 'desemprego': 2,\n",
       " 'alta,': 2,\n",
       " 'falta': 4,\n",
       " 'médicos': 2,\n",
       " '(…': 2,\n",
       " '@josromocostafi': 1,\n",
       " 'boa': 3,\n",
       " 'fazer': 7,\n",
       " 'comparação': 1,\n",
       " 'com': 20,\n",
       " 'gasolina': 1,\n",
       " 'mas,': 1,\n",
       " 'propósito,': 1,\n",
       " 'eua': 1,\n",
       " 'postal,': 1,\n",
       " 'sabia': 1,\n",
       " 'usps': 1,\n",
       " 'há': 2,\n",
       " 'também': 1,\n",
       " 'casos': 1,\n",
       " 'privatizações': 1,\n",
       " 'desastrosas': 1,\n",
       " 'portugal': 1,\n",
       " 'argentina,': 1,\n",
       " 'tiveram': 1,\n",
       " 'revertidas': 1,\n",
       " 'simples': 1,\n",
       " '@beafioroni': 2,\n",
       " '•': 3,\n",
       " 'thread': 2,\n",
       " 'caso': 2,\n",
       " 'luka': 1,\n",
       " 'magnotta': 1,\n",
       " 'ator': 2,\n",
       " 'pornô': 2,\n",
       " 'acusado': 1,\n",
       " 'matar,': 1,\n",
       " 'comer,': 1,\n",
       " 'esquartejar': 1,\n",
       " 'enviar': 3,\n",
       " 'partes': 2,\n",
       " 'corpo': 2,\n",
       " 'pelos…': 2,\n",
       " '@ptk': 1,\n",
       " 'renan': 1,\n",
       " '@luuhfelix': 2,\n",
       " 'jaee,': 2,\n",
       " 'espera': 2,\n",
       " 'seguir': 2,\n",
       " 'pelo': 4,\n",
       " '🙅🏾\\u200d♂️😉': 2,\n",
       " 'realmente': 2,\n",
       " 'dilma,': 1,\n",
       " 'oremos': 1,\n",
       " 'tornem': 1,\n",
       " 'hahahha': 1,\n",
       " 'co/edm': 1,\n",
       " 'eqk': 1,\n",
       " '@alexpressonauta': 1,\n",
       " 'resto': 2,\n",
       " 'pré': 2,\n",
       " 'sal,': 1,\n",
       " 'embraer,': 1,\n",
       " 'petrobras,': 4,\n",
       " 'alcântara,': 1,\n",
       " 'amazônia,': 1,\n",
       " 'lula': 1,\n",
       " 'preso': 1,\n",
       " 'essas': 1,\n",
       " 'pautas': 1,\n",
       " 'interessam…': 1,\n",
       " '@deborah': 1,\n",
       " 'gurgeel': 1,\n",
       " 'depende,': 1,\n",
       " 'ela': 5,\n",
       " 'pode': 4,\n",
       " 'mandada': 1,\n",
       " 'qualquer': 2,\n",
       " 'ficar': 2,\n",
       " 'olho': 3,\n",
       " 'onde': 3,\n",
       " 'vai,': 1,\n",
       " 'através': 1,\n",
       " 'código': 1,\n",
       " 'rastreamento': 3,\n",
       " 'night': 1,\n",
       " 'downtown': 1,\n",
       " 'santoandre': 1,\n",
       " 'noite': 1,\n",
       " 'urbanphotography': 1,\n",
       " 'city': 1,\n",
       " 'pça': 1,\n",
       " 'iv': 1,\n",
       " 'centenário': 1,\n",
       " 'co/ul': 1,\n",
       " 'qtflbeh': 1,\n",
       " 'to': 2,\n",
       " 'levando': 1,\n",
       " 'minha': 4,\n",
       " 'identidade': 1,\n",
       " 'hj': 2,\n",
       " 'passar': 1,\n",
       " 'tomara': 1,\n",
       " 'meus': 1,\n",
       " 'álbuns': 1,\n",
       " 'já': 8,\n",
       " 'tenham': 1,\n",
       " 'chegado': 1,\n",
       " '@queenmychem': 1,\n",
       " 'vou': 4,\n",
       " 'doar,': 1,\n",
       " 'nao': 1,\n",
       " 'tive': 1,\n",
       " 'tempo': 2,\n",
       " 'ir': 2,\n",
       " 'levar': 1,\n",
       " 'nos': 11,\n",
       " '@capitaobrasilll': 1,\n",
       " '@malzonewild': 1,\n",
       " '@arthurweint': 1,\n",
       " '@lindoso': 1,\n",
       " 'stanley': 1,\n",
       " 'daí': 1,\n",
       " 'frete': 3,\n",
       " 'custa': 1,\n",
       " 'r': 11,\n",
       " ',': 15,\n",
       " '(que': 1,\n",
       " 'inclusive': 2,\n",
       " 'menor)': 1,\n",
       " 'regi…': 1,\n",
       " '@brasauscolombia': 1,\n",
       " '@aandrade': 2,\n",
       " 'reclamou': 2,\n",
       " 'rsrsrs': 2,\n",
       " '@jpeax': 1,\n",
       " 'produto': 2,\n",
       " 'saiu': 2,\n",
       " 'entrega': 4,\n",
       " 'destinatário': 2,\n",
       " 'co/zvr': 2,\n",
       " 'm': 3,\n",
       " 'srkp': 2,\n",
       " '@mariadorosario': 1,\n",
       " 'audiência': 1,\n",
       " 'comissão': 1,\n",
       " 'legislação': 1,\n",
       " 'participativa': 1,\n",
       " 'realizamos': 1,\n",
       " 'parceria': 1,\n",
       " 'assembleia': 4,\n",
       " 'rs': 2,\n",
       " 'r…': 1,\n",
       " 'esquerdopata': 1,\n",
       " 'acha': 1,\n",
       " 'ruim': 1,\n",
       " '👊💪': 1,\n",
       " 'privatizatudo': 1,\n",
       " 'co/pmm': 1,\n",
       " 'z': 1,\n",
       " 'zo': 1,\n",
       " '@homefilatelista': 1,\n",
       " 'imagem': 2,\n",
       " 'destacada': 2,\n",
       " 'vemos': 2,\n",
       " 'silhueta': 2,\n",
       " 'cabeça': 2,\n",
       " 'contém': 2,\n",
       " 'muitos': 4,\n",
       " 'outras': 5,\n",
       " 'trata': 2,\n",
       " 'alegoria': 2,\n",
       " 'utilizada': 2,\n",
       " 'gerente': 3,\n",
       " 'salário': 3,\n",
       " 'benefícios': 3,\n",
       " 'saúde': 4,\n",
       " 'vt': 3,\n",
       " 'local': 3,\n",
       " 'bh': 3,\n",
       " 'horário': 3,\n",
       " 'segunda': 3,\n",
       " 'á': 3,\n",
       " 'sexta–': 1,\n",
       " 'feira': 2,\n",
       " 'horas': 2,\n",
       " 'ás': 1,\n",
       " 'atividades': 1,\n",
       " 'gestão': 1,\n",
       " 'agência,': 1,\n",
       " 'vendas': 1,\n",
       " 'equipe': 1,\n",
       " 'co/fngjxvgfdm': 1,\n",
       " '@epicastpodcast': 1,\n",
       " 'chegou': 1,\n",
       " 'gráfica': 1,\n",
       " 'agora,': 1,\n",
       " 'lá': 3,\n",
       " 'autografar': 1,\n",
       " 'final': 1,\n",
       " 'nada': 3,\n",
       " 'nunca': 3,\n",
       " 'mudar': 2,\n",
       " 'entre': 3,\n",
       " 'nossa': 2,\n",
       " 'amizade': 1,\n",
       " 'importa': 1,\n",
       " 'aconteça': 1,\n",
       " '(e': 2,\n",
       " 'olha': 1,\n",
       " 'tivemos': 1,\n",
       " 'provas': 1,\n",
       " 'vivas': 1,\n",
       " 'disso': 1,\n",
       " 'kkkk)': 1,\n",
       " 'te': 1,\n",
       " 'amo': 1,\n",
       " 'meu': 5,\n",
       " 'amor,': 1,\n",
       " 'prefira': 1,\n",
       " 'modo': 1,\n",
       " 'noturno': 1,\n",
       " '@jjkscore': 1,\n",
       " 'consigo': 3,\n",
       " 'ver': 5,\n",
       " 'triste': 2,\n",
       " 'tl': 2,\n",
       " 'velho,': 2,\n",
       " 'tentar': 3,\n",
       " 'ajudar,': 2,\n",
       " 'tô': 3,\n",
       " 'mandando': 2,\n",
       " 'anônim…': 1,\n",
       " 'caraleo': 1,\n",
       " 'viu': 1,\n",
       " 'co/oeceiwqdia': 1,\n",
       " 'suspeitos': 1,\n",
       " 'assaltar': 1,\n",
       " 'presos': 1,\n",
       " 'serrana': 1,\n",
       " 'co/bnjnzc': 1,\n",
       " 'g': 1,\n",
       " 'n': 5,\n",
       " '@jaoike': 1,\n",
       " '@clubemondoverde': 1,\n",
       " 'perto': 1,\n",
       " 'antes': 2,\n",
       " 'bradesco': 1,\n",
       " 'pagamento': 3,\n",
       " 'transferência': 1,\n",
       " 'bancária': 1,\n",
       " 'posso': 2,\n",
       " 'negociar': 1,\n",
       " 'formas': 1,\n",
       " 'reservo': 1,\n",
       " 'máximo': 2,\n",
       " 'dias,': 1,\n",
       " 'vez': 1,\n",
       " 'mando': 1,\n",
       " 'dias': 2,\n",
       " 'úteis': 1,\n",
       " 'após': 2,\n",
       " 'cair': 1,\n",
       " '(demora': 1,\n",
       " 'média': 1,\n",
       " 'semana': 1,\n",
       " 'chegar)': 1,\n",
       " 'dúvidas': 1,\n",
       " 'demais': 1,\n",
       " 'informações,': 1,\n",
       " 'dm': 1,\n",
       " '@cwamilapower': 1,\n",
       " '+': 2,\n",
       " 'imprimir': 1,\n",
       " 'poder': 1,\n",
       " 'despachar': 1,\n",
       " 'basicamente': 1,\n",
       " 'isso,': 2,\n",
       " 'tiver': 1,\n",
       " 'alguma': 1,\n",
       " 'dúvida': 1,\n",
       " 'chamar': 1,\n",
       " '@bhcbdv': 2,\n",
       " 'sext…': 2,\n",
       " '🖇from': 1,\n",
       " 'anônimo': 1,\n",
       " '🖇to': 1,\n",
       " '@taelitw': 1,\n",
       " 'palavras': 1,\n",
       " 'seriam': 1,\n",
       " 'capazes': 1,\n",
       " 'expressar': 1,\n",
       " 'amor': 1,\n",
       " 'sinto': 1,\n",
       " 'ti,': 1,\n",
       " 'durante': 1,\n",
       " 'anos': 2,\n",
       " 'perguntando': 1,\n",
       " 'valeria': 1,\n",
       " 'pena': 1,\n",
       " 'talvez': 2,\n",
       " 'tenha': 2,\n",
       " 'certeza': 1,\n",
       " 'espero': 2,\n",
       " 'importe': 1,\n",
       " 'quão': 1,\n",
       " 'melosa': 1,\n",
       " 'vezes': 1,\n",
       " 'quero': 1,\n",
       " '@mercadolivre': 1,\n",
       " 'endereço': 1,\n",
       " 'entrega,': 1,\n",
       " 'pegar': 1,\n",
       " 'compra': 3,\n",
       " 'algum': 1,\n",
       " 'lugar': 2,\n",
       " 'dar': 1,\n",
       " 'jeito': 2,\n",
       " 'entrar': 1,\n",
       " 'contato': 2,\n",
       " 'atual': 2,\n",
       " 'morador': 1,\n",
       " 'residência': 1,\n",
       " 'agradeço': 1,\n",
       " 'ajuda': 1,\n",
       " '^^': 1,\n",
       " '@reggianidavi': 1,\n",
       " 'erro': 1,\n",
       " 'cidadão': 2,\n",
       " 'atualizando': 1,\n",
       " 'toda': 2,\n",
       " 'hora': 3,\n",
       " 'fico': 1,\n",
       " 'morrer': 1,\n",
       " 'estou': 1,\n",
       " 'esperando': 4,\n",
       " 'queria': 1,\n",
       " 'receber': 1,\n",
       " 'anônimos': 2,\n",
       " '@pestenegrapcst': 1,\n",
       " 'porra,ta': 1,\n",
       " 'meses': 1,\n",
       " 'liminar,ta': 1,\n",
       " 'vindo': 2,\n",
       " 'via': 1,\n",
       " 'sa': 1,\n",
       " 'porra': 2,\n",
       " 'vire': 1,\n",
       " 'prime': 4,\n",
       " 'conteúdo': 1,\n",
       " 'infinito': 1,\n",
       " 'coisinhas': 1,\n",
       " 'escrevo': 1,\n",
       " 'conversando': 1,\n",
       " 'tweets': 1,\n",
       " '@daircarvalho': 1,\n",
       " 'mundo,': 1,\n",
       " 'principalmente': 1,\n",
       " 'moço': 1,\n",
       " '/': 2,\n",
       " 'trabalhadores': 2,\n",
       " 'co/y': 1,\n",
       " 'mdnkjaim': 1,\n",
       " 'opa': 1,\n",
       " 'poderia': 1,\n",
       " 'porfavor': 1,\n",
       " 'co/fuqxckylvb': 1,\n",
       " 'necessidade': 1,\n",
       " 'eletrobras': 3,\n",
       " 'sequer': 1,\n",
       " 'muitas': 1,\n",
       " 'agências': 2,\n",
       " 'bancárias': 1,\n",
       " 'acordem': 1,\n",
       " '@leandro': 1,\n",
       " 'jcampos': 1,\n",
       " '@folha': 2,\n",
       " 'sim': 1,\n",
       " 'cara,': 1,\n",
       " 'entendo': 3,\n",
       " 'rentabilidade': 1,\n",
       " 'trabalhei': 1,\n",
       " 'logística': 1,\n",
       " 'operação': 1,\n",
       " 'bato': 1,\n",
       " 'tecla': 1,\n",
       " 'monopólio,': 2,\n",
       " 'tema': 1,\n",
       " 'própria': 2,\n",
       " 'faz': 1,\n",
       " 'ficando': 1,\n",
       " 'claro': 1,\n",
       " 'interesse': 3,\n",
       " '@senhormauricio': 1,\n",
       " '@sergiorevere': 1,\n",
       " '@lolaescreva': 1,\n",
       " '@haddad': 1,\n",
       " 'fernando': 1,\n",
       " 'engraçado': 1,\n",
       " 'petista': 1,\n",
       " 'pedindo': 1,\n",
       " 'prova': 1,\n",
       " 'esqueceram': 1,\n",
       " 'oas,': 1,\n",
       " 'odebrecht,': 1,\n",
       " 'delação': 1,\n",
       " 'palocci': 1,\n",
       " 'maracutaias': 1,\n",
       " 'comprovadas': 1,\n",
       " 'culpado': 1,\n",
       " 'queiroz,': 1,\n",
       " 'deve': 2,\n",
       " 'sido': 1,\n",
       " 'desviou': 1,\n",
       " 'grana': 1,\n",
       " '@ivannescaa': 1,\n",
       " '@bethguimares': 1,\n",
       " 'carece': 1,\n",
       " 'digreção': 1,\n",
       " 'basta': 1,\n",
       " 'olhar': 1,\n",
       " 'funcionários': 3,\n",
       " 'gritando': 1,\n",
       " 'privatiza': 1,\n",
       " '@nathansg': 1,\n",
       " 'cuidaram': 1,\n",
       " 'muito': 2,\n",
       " 'dele': 1,\n",
       " 'tempo,': 1,\n",
       " 'aposto': 1,\n",
       " 'greve': 4,\n",
       " 'tocantins,': 1,\n",
       " 'marcada': 1,\n",
       " 'próxima': 1,\n",
       " 'quarta': 2,\n",
       " 'co/x': 1,\n",
       " 'apviatbz': 1,\n",
       " '@nesleykent': 1,\n",
       " 'cade': 2,\n",
       " '@dilmabr': 2,\n",
       " 'precisamos': 2,\n",
       " 'agora': 2,\n",
       " 'vida': 3,\n",
       " '@heldercervantes': 1,\n",
       " '@typisktugisk': 1,\n",
       " 'prenderam': 1,\n",
       " 'marco': 1,\n",
       " '@o': 1,\n",
       " 'antagonista': 1,\n",
       " 'pior': 1,\n",
       " 'roubar': 1,\n",
       " 'petrobras': 1,\n",
       " 'inocente': 1,\n",
       " '@emrcanelas': 1,\n",
       " '@herminiocerq': 2,\n",
       " '@cristasassuncao': 2,\n",
       " 'nacionalizar': 1,\n",
       " 'defende': 1,\n",
       " 'das': 3,\n",
       " 'duas': 1,\n",
       " 'demagogia': 1,\n",
       " 'enganar': 1,\n",
       " 'tolos': 1,\n",
       " 'problema': 2,\n",
       " 'mental': 1,\n",
       " 'grave': 1,\n",
       " '@uolnoticias': 1,\n",
       " 'bozo': 2,\n",
       " 'tá': 5,\n",
       " 'fazendo': 2,\n",
       " 'destruí': 1,\n",
       " 'brasileiro,ele': 1,\n",
       " 'mede': 1,\n",
       " 'esfosso': 1,\n",
       " 'redução': 1,\n",
       " 'verbas': 1,\n",
       " 'educação,agora': 1,\n",
       " 'canalha': 2,\n",
       " 'igual': 1,\n",
       " '@sansadu': 1,\n",
       " '@herculanofagu': 1,\n",
       " '@allantercalivre': 1,\n",
       " 'levou': 2,\n",
       " 'cassação': 1,\n",
       " 'mandato': 1,\n",
       " 'collor': 1,\n",
       " 'processos': 1,\n",
       " 'iniciaram': 1,\n",
       " 'mensalão': 4,\n",
       " 'aprendiz': 1,\n",
       " 'sem': 6,\n",
       " 'co/i': 1,\n",
       " 'sll': 1,\n",
       " 'kmzv': 1,\n",
       " '@iaragb': 5,\n",
       " 'resultado': 5,\n",
       " 'indiciou': 5,\n",
       " 'pessoas,': 5,\n",
       " 'fez': 6,\n",
       " 'propostas': 5,\n",
       " 'aumento': 5,\n",
       " 'rigor': 5,\n",
       " 'aplicação': 5,\n",
       " 'verbas…': 5,\n",
       " 'haverá': 2,\n",
       " 'atender': 2,\n",
       " 'todos,': 2,\n",
       " 'diz': 2,\n",
       " 'ex': 2,\n",
       " 'funcionário': 3,\n",
       " 'co/duzyf': 1,\n",
       " 'td': 1,\n",
       " 'f': 1,\n",
       " 'virar': 1,\n",
       " 'co/j': 1,\n",
       " 'hqcrei': 1,\n",
       " 't': 1,\n",
       " 'ameaçados': 1,\n",
       " 'defendê': 1,\n",
       " 'los': 1,\n",
       " 'co/q': 1,\n",
       " 'gwegzpvl': 1,\n",
       " 'fui': 2,\n",
       " 'tia,': 1,\n",
       " 'adriel,': 1,\n",
       " 'adriele': 1,\n",
       " 'jogar': 1,\n",
       " 'esteio': 1,\n",
       " 'agr': 1,\n",
       " 'canoas': 1,\n",
       " 'ronaldinho': 1,\n",
       " 'ia': 1,\n",
       " 'sentir': 2,\n",
       " 'orgulho': 1,\n",
       " 'desses': 2,\n",
       " 'rolê': 1,\n",
       " 'aleatório': 1,\n",
       " '@emrsnf': 1,\n",
       " 'br': 3,\n",
       " '@prefeituradegyn': 1,\n",
       " '⚠': 1,\n",
       " 'garantiu': 1,\n",
       " 'cpf': 1,\n",
       " 'filho': 1,\n",
       " 'documento': 2,\n",
       " 'obrigatório': 1,\n",
       " 'realizar': 1,\n",
       " 'matrícula': 1,\n",
       " 'escolas': 1,\n",
       " 'cmeis': 1,\n",
       " 'de…': 2,\n",
       " '@intoyurik': 1,\n",
       " 'abre': 2,\n",
       " 'concurso': 2,\n",
       " 'escolha': 2,\n",
       " 'selo': 3,\n",
       " 'natal': 2,\n",
       " 'co/z': 1,\n",
       " 'azmw': 1,\n",
       " 'aac': 1,\n",
       " 'conmebol': 1,\n",
       " 'fizer': 1,\n",
       " 'novo': 1,\n",
       " 'aquele': 2,\n",
       " 'far': 1,\n",
       " 'play': 1,\n",
       " 'semifinalistas,': 1,\n",
       " 'seria': 1,\n",
       " 'romildo': 1,\n",
       " 'assinar,': 1,\n",
       " 'esfregar': 1,\n",
       " 'saco': 1,\n",
       " 'mandar': 2,\n",
       " 'volta': 1,\n",
       " 'sei': 1,\n",
       " '@siqueirambl': 3,\n",
       " 'vereador': 4,\n",
       " 'cidade': 5,\n",
       " 'rio': 4,\n",
       " 'janeiro,': 4,\n",
       " '@carlosbolsonaro': 5,\n",
       " 'pediu': 4,\n",
       " 'licença': 4,\n",
       " 'remuneração': 4,\n",
       " 'cargo': 4,\n",
       " 'vamos': 4,\n",
       " 'since…': 3,\n",
       " '🔥hot': 1,\n",
       " 'take🔥': 1,\n",
       " 'lançou': 1,\n",
       " 'evitar': 1,\n",
       " 'profecia': 1,\n",
       " \"'correios\": 1,\n",
       " 'tornarem': 1,\n",
       " \"amazon'\": 1,\n",
       " 'concretize': 1,\n",
       " 'bélgica': 1,\n",
       " 'falar': 2,\n",
       " 'diferenças': 1,\n",
       " 'seres': 1,\n",
       " 'humanos': 1,\n",
       " 'seja': 1,\n",
       " 'for': 1,\n",
       " 'aparência': 1,\n",
       " 'somos': 1,\n",
       " 'iguais': 1,\n",
       " 'b': 1,\n",
       " 'co/xrgm': 1,\n",
       " 'otqy': 1,\n",
       " 'jm': 1,\n",
       " 'grf': 1,\n",
       " '@silasvrb': 1,\n",
       " 'estadia': 1,\n",
       " 'horror': 1,\n",
       " 'deus': 2,\n",
       " 'co/xjjal': 1,\n",
       " 'ho': 1,\n",
       " 'mesmo,': 1,\n",
       " 'foda': 2,\n",
       " 'demaaaais': 1,\n",
       " 'vende': 2,\n",
       " 'logo': 1,\n",
       " 'tão': 2,\n",
       " 'co/eyc': 1,\n",
       " 'yu': 1,\n",
       " 'aw': 1,\n",
       " 'privatizarem': 1,\n",
       " 'valer': 1,\n",
       " 'menos': 2,\n",
       " 'co/s': 1,\n",
       " 'bcr': 1,\n",
       " 'djxc': 1,\n",
       " '=': 2,\n",
       " 'co/vktba': 2,\n",
       " 'qz': 2,\n",
       " '@leandroruschel': 1,\n",
       " 'esquerd…': 1,\n",
       " 'merda': 4,\n",
       " 'concordo': 1,\n",
       " 'essa': 3,\n",
       " 'precisa': 1,\n",
       " 'privatizada': 1,\n",
       " 'brasil,': 1,\n",
       " 'entreguista': 1,\n",
       " 'fascista': 1,\n",
       " '@clarissadelune': 1,\n",
       " 'aí': 1,\n",
       " 'resposta': 1,\n",
       " 'fácil,': 1,\n",
       " 'parece': 1,\n",
       " 'começo': 1,\n",
       " 'jeito,': 1,\n",
       " 'criar': 1,\n",
       " 'demanda': 1,\n",
       " 'aquela': 2,\n",
       " 'localidade': 1,\n",
       " 'torne': 1,\n",
       " 'atrativa': 1,\n",
       " 'iniciativa': 1,\n",
       " 'privada': 2,\n",
       " 'tendo': 1,\n",
       " 'demanda,': 1,\n",
       " 'poderiam': 1,\n",
       " 'aproveitar': 1,\n",
       " 'centros': 1,\n",
       " 'distribuição': 1,\n",
       " 'correios+': 1,\n",
       " '@correios': 2,\n",
       " 'anon': 2,\n",
       " '@jiminseason': 1,\n",
       " 'mande': 1,\n",
       " 'mimos': 1,\n",
       " '😔😔😔👍👍👍👍': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cria database setarada de relevantes e irrelevantes\n",
    "data_frame_rlevantes = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==1]\n",
    "serie_relevantes=pd.Series(data_frame_rlevantes[\"Treinamento\"])\n",
    "data_frame_nao_rlevantes = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==0]\n",
    "serie_nao_relevantes=pd.Series(data_frame_nao_rlevantes[\"Treinamento\"])\n",
    "#conta a incidencia de cada palavra\n",
    "contagem_relevantes={}\n",
    "for T in serie_relevantes:\n",
    "    contagem_relevantes=conta_palavra(T,contagem_relevantes)\n",
    "contagem_nao_relevantes={}\n",
    "for T in serie_nao_relevantes:\n",
    "    serie_nao_relevantes=conta_palavra(T,contagem_nao_relevantes)\n",
    "\n",
    "#associa um valor de probabilidade\n",
    "probrev={}\n",
    "\n",
    "#formato {palavra:valor}\n",
    "probnorev={}\n",
    "#formato {palavra:valor}\n",
    "serie_nao_relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoth = 1/1000000 #é uma estimativa e deve mudar\n",
    "# defini probabilidade de ser relevante:\n",
    "def relevante(tweet):\n",
    "    t = clean(tweet)\n",
    "    prob = 1\n",
    "    for p in t:\n",
    "        if p in probrev:\n",
    "            prob = prob*(probrev(p)+smoth)\n",
    "        else:\n",
    "            prob = prob*(smoth)\n",
    "    prob = prev\n",
    "# defini probabilidade de ser irrelevante:\n",
    "def relevante(tweet):\n",
    "    t = clean(tweet)\n",
    "    prob = 1\n",
    "    for p in t:\n",
    "        if p in probnorev:\n",
    "            prob = prob*(probnorev(p)+smoth)\n",
    "        else:\n",
    "            prob = prob*(smoth)\n",
    "    prob = pnorev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara (tweet):\n",
    "    r = relevante(tweet)\n",
    "    nor = irrelevante(tweet)\n",
    "    return r>nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-87-590e40ef14d4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-87-590e40ef14d4>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    arquivo =\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "arquivo = \n",
    "rev = 0\n",
    "norev = 0\n",
    "for txt in arquivo:\n",
    "    if compara (txt):\n",
    "        rev +=1\n",
    "    else:\n",
    "        norev+=1\n",
    "print (\"a probabilidade de ser relevante é {}\".format(rev/arquivo.len()))\n",
    "print (\"a probabilidade de não ser relevante é {}\".format(rev/arquivo.len()))\n",
    "if rev/arquivo.len() < 0.9*prev:\n",
    "    print (\"poucos relevantes\")\n",
    "elif rev/arquivo.len() > 1.1*prev:\n",
    "    print (\"muitos relevantes\")\n",
    "else:\n",
    "    print (\"ok: {} veze o esperado\".format (rev/arquivo.len()/prev))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
