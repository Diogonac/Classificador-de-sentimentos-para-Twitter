{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: _____\n",
    "\n",
    "Nome: Diogo Nobre de Araujo Cintra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-797685fe92f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2305\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2306\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2307\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2308\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<C:\\Users\\diogo\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\decorator.py:decorator-gen-109>\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\IPython\\core\\magics\\pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   3370\u001b[0m         \"\"\"\n\u001b[0;32m   3371\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3372\u001b[1;33m         \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3374\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[1;34m(gui, gui_select)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \"\"\"\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange\n",
    "from numpy import percentile\n",
    "import numpy as np\n",
    "import os\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@Ciencia dos dados***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Correios'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "#### 0 = irrelevante\n",
    "#### 1 = relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREINAMENTO = pd.read_excel('Correios.xlsx',sheet_name = 'Treinamento')\n",
    "TESTE = pd.read_excel('Correios.xlsx',sheet_name = 'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREINAMENTO_RELEVANTE = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==1]\n",
    "TREINAMENTO_IRRELEVANTE = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==0]\n",
    "\n",
    "def clean(text):\n",
    "    punctuation = '[!\\-.:?;#$%&*_1234567890\"]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_relevante = \" \".join(TREINAMENTO_RELEVANTE['Treinamento'])\n",
    "texto_relevante_1 = clean(texto_relevante)\n",
    "texto_relevante_2 = texto_relevante_1.split()\n",
    "texto_relevante_3 = []\n",
    "\n",
    "texto_irrelevante = \" \".join(TREINAMENTO_IRRELEVANTE['Treinamento'])\n",
    "texto_irrelevante_1 = clean(texto_irrelevante)\n",
    "texto_irrelevante_2 = texto_irrelevante_1.split()\n",
    "texto_irrelevante_3 = []\n",
    "\n",
    "treinamento = \" \".join(TREINAMENTO['Treinamento'])\n",
    "treinamento_1 = clean(treinamento)\n",
    "treinamento_2 = treinamento_1.split()\n",
    "treinamento_3 = []\n",
    "\n",
    "for e in range(len(texto_relevante_2)-1):\n",
    "    if texto_relevante_2[e] != 'rt' and texto_relevante_2[e][0] != '@':     \n",
    "        texto_relevante_3.append(texto_relevante_2[e])    \n",
    "        \n",
    "for e in range(len(texto_irrelevante_2)-1):\n",
    "    if texto_irrelevante_2[e] != 'rt' and texto_irrelevante_2[e][0] != '@':     \n",
    "        texto_irrelevante_3.append(texto_irrelevante_2[e]) \n",
    "        \n",
    "for e in range(len(treinamento_2)-1):\n",
    "    if treinamento_2[e] != 'rt' and treinamento_2[e][0] != '@':     \n",
    "        treinamento_3.append(treinamento_2[e])\n",
    "        \n",
    "texto_relevante_4 = pd.Series(texto_relevante_3)\n",
    "texto_irrelevante_4 = pd.Series(texto_irrelevante_3)\n",
    "treinamento_4 = pd.Series(treinamento_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de uma palavra ser relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4027777777777778"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total_amostral = treinamento_4.value_counts()\n",
    "#total_relevante = texto_relevante_4.value_counts()\n",
    "\n",
    "TREINAMENTO.Classificacao.value_counts()\n",
    "prev = 120/300 #probabilidade de ser relevante geral\n",
    "\n",
    "total_amostral = len(treinamento_4)-1\n",
    "total_relevante = len(texto_relevante_4)\n",
    "prob_relevante = total_relevante/total_amostral\n",
    "prob_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de uma palavra ser irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5972222222222222"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total_amostral = treinamento_4.value_counts()\n",
    "#total_relevante = texto_relevante_4.value_counts()\n",
    "\n",
    "TREINAMENTO.Classificacao.value_counts()\n",
    "prev = 180/300 #probabilidade de ser relevante geral\n",
    "\n",
    "total_amostral = len(treinamento_4)-1\n",
    "total_irrelevante = len(texto_irrelevante_4)\n",
    "prob_irrelevante = total_irrelevante/total_amostral\n",
    "prob_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#probabilidade de ser relevante\n",
    "TREINAMENTO.Classificacao.value_counts()\n",
    "prev = 120/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidade de n√£o ser relevante\n",
    "pnorev = 180/300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contador das palavras\n",
    "def conta_palavra(texto, dic):\n",
    "    texto_sem_pontuacao = clean(texto)\n",
    "    palavras_do_texto = texto_sem_pontuacao.split()\n",
    "    palavras=dic\n",
    "    for p in palavras_do_texto:\n",
    "        if p in palavras:\n",
    "            palavras[p]+=1\n",
    "        else:\n",
    "            palavras[p]=1\n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rt': 69,\n",
       " '@arthurmoledoval': 17,\n",
       " 'o': 104,\n",
       " 'governo': 23,\n",
       " 'recomendou': 15,\n",
       " 'ao': 22,\n",
       " 'bndes': 16,\n",
       " 'que': 103,\n",
       " 'os': 66,\n",
       " 'estudos': 15,\n",
       " 'sobre': 22,\n",
       " 'uma': 44,\n",
       " 'eventual': 15,\n",
       " 'privatiza√ß√£o': 20,\n",
       " 'dos': 58,\n",
       " 'correios': 135,\n",
       " 'fiquem': 15,\n",
       " 'prontos': 15,\n",
       " 'em': 43,\n",
       " 'at√©': 16,\n",
       " 'mese‚Ä¶': 15,\n",
       " '@casonatogabriel': 11,\n",
       " 'a': 84,\n",
       " 'amazon,': 14,\n",
       " 'empresa': 16,\n",
       " 'na': 34,\n",
       " 'qual': 12,\n",
       " 'queremos': 11,\n",
       " 'transformar': 22,\n",
       " 'correios,': 26,\n",
       " 'lan√ßa': 11,\n",
       " 'hoje': 15,\n",
       " 'no': 37,\n",
       " 'brasil': 15,\n",
       " 'programa': 11,\n",
       " 'prime,': 11,\n",
       " 'd√°': 11,\n",
       " 'aos': 15,\n",
       " 'seus': 12,\n",
       " 'ass‚Ä¶': 11,\n",
       " '@willianlofy': 1,\n",
       " 'usam': 2,\n",
       " 'quem': 3,\n",
       " 'quer,': 1,\n",
       " 'como': 15,\n",
       " '‚Äútodos‚Äù': 1,\n",
       " 'sabem,': 1,\n",
       " 'monop√≥lio': 4,\n",
       " '√©': 38,\n",
       " 'somente': 1,\n",
       " 'daquelas': 1,\n",
       " 'cartinhas': 1,\n",
       " 'ningu√©m': 2,\n",
       " 'mais': 16,\n",
       " 'usa': 1,\n",
       " 'pessoa': 3,\n",
       " 'vai': 14,\n",
       " 'dirigir': 1,\n",
       " 'de': 120,\n",
       " 'madrugada': 1,\n",
       " 'achando': 1,\n",
       " 'braian': 1,\n",
       " 'ai': 3,\n",
       " 'dps': 1,\n",
       " 'fica': 2,\n",
       " 'um': 17,\n",
       " 'm√™s': 2,\n",
       " 'indo': 2,\n",
       " 'caixinha': 2,\n",
       " 'todo': 6,\n",
       " 'dia': 3,\n",
       " 'temendo': 1,\n",
       " 'multa': 1,\n",
       " 'nova': 3,\n",
       " 'tem': 12,\n",
       " 'se': 25,\n",
       " 'fuder': 1,\n",
       " 'msm': 2,\n",
       " 'mas': 12,\n",
       " 'deu': 3,\n",
       " 'tudo': 5,\n",
       " 'certo,': 1,\n",
       " 'n√£o': 33,\n",
       " 'passei': 3,\n",
       " 'acima': 1,\n",
       " 'do': 39,\n",
       " 'limite': 1,\n",
       " 'üòÇüòÇüòÇ': 2,\n",
       " 'uns': 2,\n",
       " 'males': 1,\n",
       " 'vem': 3,\n",
       " 'pra': 17,\n",
       " 'bem': 8,\n",
       " 'sdd': 1,\n",
       " 'quando': 6,\n",
       " 'tinha': 1,\n",
       " 'aqueles': 3,\n",
       " 'an√¥nimos,': 1,\n",
       " 'eu': 21,\n",
       " 'adorava': 1,\n",
       " 'foi': 8,\n",
       " 'mesmo': 12,\n",
       " 'melhor': 1,\n",
       " 'ano': 1,\n",
       " '@thefaceofnike': 1,\n",
       " 'han,': 1,\n",
       " 'aqui': 5,\n",
       " 'nesse': 2,\n",
       " 'pique,': 1,\n",
       " 'bom': 3,\n",
       " 'vermelha': 1,\n",
       " 'passa': 2,\n",
       " 'caminh√£o': 1,\n",
       " 'permiss√£o,': 1,\n",
       " 'as': 7,\n",
       " 'carreta': 2,\n",
       " 'bagulho': 1,\n",
       " 'bate': 1,\n",
       " 'escala': 1,\n",
       " 'richter': 1,\n",
       " '@eniberto': 1,\n",
       " 'real': 1,\n",
       " '@rafaiovanovichi': 1,\n",
       " 'ele': 2,\n",
       " 'disse': 1,\n",
       " 'gosta': 1,\n",
       " 'ti': 1,\n",
       " 'quadrilha': 1,\n",
       " 'alvo': 1,\n",
       " 'da': 26,\n",
       " 'pf': 1,\n",
       " 'tocantins': 1,\n",
       " 'vendia': 1,\n",
       " 'moeda': 1,\n",
       " 'falsa': 1,\n",
       " 'nas': 3,\n",
       " 'redes': 1,\n",
       " 'sociais': 1,\n",
       " 'e': 49,\n",
       " 'enviava': 1,\n",
       " 'pelos': 13,\n",
       " 'https': 45,\n",
       " '//t': 45,\n",
       " 'co/hn': 1,\n",
       " 'hxpjwrp': 1,\n",
       " 'pol√≠cia': 2,\n",
       " 'procura': 1,\n",
       " 'por': 18,\n",
       " 'homem': 4,\n",
       " 'roubou': 1,\n",
       " 'ag√™ncia': 5,\n",
       " 'japonvar': 1,\n",
       " 'co/buhjm': 1,\n",
       " 'ysu': 1,\n",
       " '@ph': 3,\n",
       " 'limass': 3,\n",
       " 'pergunta': 1,\n",
       " 'algu√©m': 2,\n",
       " 'genuinamente': 1,\n",
       " 'opini√£o': 1,\n",
       " 'formada': 1,\n",
       " 'assunto': 3,\n",
       " 'solu√ß√£o': 1,\n",
       " 'privatizadora': 1,\n",
       " 'conseguiria': 1,\n",
       " 'suprir': 1,\n",
       " 'v√°cuo': 1,\n",
       " 'servi√ßo': 4,\n",
       " 'cidades': 2,\n",
       " 'menores': 1,\n",
       " 'quais': 4,\n",
       " 'equivalente': 1,\n",
       " 'privado': 1,\n",
       " 'teria': 2,\n",
       " 'lucro': 2,\n",
       " 'compre': 1,\n",
       " 'atacado': 1,\n",
       " 'varejo': 1,\n",
       " 'enviamos': 1,\n",
       " 'para': 20,\n",
       " 'ou': 8,\n",
       " 'transportadora': 1,\n",
       " 'acesse': 1,\n",
       " 'co/a': 2,\n",
       " 'ux': 1,\n",
       " 'wbsxp': 1,\n",
       " 'natuvel': 1,\n",
       " 'produtosnaturais': 1,\n",
       " 'revenda': 1,\n",
       " 'rendaextra': 1,\n",
       " 'emagrecer': 1,\n",
       " 'dieta': 2,\n",
       " 'fitness': 1,\n",
       " 'saude': 1,\n",
       " 'perderpeso': 1,\n",
       " 'queimagordura': 1,\n",
       " 'atacadonaturais': 1,\n",
       " 'secabarriga': 1,\n",
       " 'co/': 5,\n",
       " 'mkup': 1,\n",
       " 'gn': 1,\n",
       " 'j': 1,\n",
       " '@ferraz': 1,\n",
       " 'rodolpho': 1,\n",
       " 'sim,': 7,\n",
       " 'deixou': 2,\n",
       " 'novamente': 1,\n",
       " '@hebertkiss': 4,\n",
       " 'dilma': 10,\n",
       " 'afirmou': 6,\n",
       " 'esse': 12,\n",
       " 'quer': 8,\n",
       " 'numa': 10,\n",
       " 'amazon': 19,\n",
       " 'anta,': 6,\n",
       " 'plano': 10,\n",
       " 's√≥': 16,\n",
       " 'esquerdopat‚Ä¶': 4,\n",
       " '@tabataamaralsp': 4,\n",
       " 'nem': 3,\n",
       " 'carta': 3,\n",
       " '@ilysimaria': 1,\n",
       " 'oi': 2,\n",
       " 'aceito': 2,\n",
       " 'ganhar': 2,\n",
       " 'dessess': 2,\n",
       " 'co/vut': 2,\n",
       " 'tvd': 2,\n",
       " 'q': 10,\n",
       " '@bdaysbangtan': 3,\n",
       " '‚òÜ': 3,\n",
       " 'motivos': 3,\n",
       " 'voc√™s': 5,\n",
       " 'podem': 4,\n",
       " 'ter': 7,\n",
       " 'recebido': 3,\n",
       " 'card': 4,\n",
       " 'bdays': 3,\n",
       " 'armys': 3,\n",
       " 'ainda': 6,\n",
       " '(thread)': 3,\n",
       " 'voc√™': 9,\n",
       " 'apenas': 5,\n",
       " 'inscreveu': 3,\n",
       " 'e‚Ä¶': 3,\n",
       " 'disser': 1,\n",
       " 'trabalho': 4,\n",
       " 'me': 5,\n",
       " 'deixaria': 1,\n",
       " 'tocar': 1,\n",
       " 'seu': 9,\n",
       " 'pacote': 1,\n",
       " '‚Äî': 1,\n",
       " 'skkskssk': 1,\n",
       " 'co/haq': 1,\n",
       " 'qwjlwn': 1,\n",
       " 'carlos': 1,\n",
       " 'v√™': 1,\n",
       " 'fala': 1,\n",
       " 'algo': 2,\n",
       " 'todos': 3,\n",
       " 'est√£o': 3,\n",
       " 'vendo': 1,\n",
       " 'est√°': 5,\n",
       " 'frente': 2,\n",
       " 'vender': 2,\n",
       " 'estatal': 5,\n",
       " 'deveria': 1,\n",
       " 'ser': 12,\n",
       " 'fechada': 1,\n",
       " 'pela': 2,\n",
       " 'perda': 1,\n",
       " 'sentido': 1,\n",
       " 'existir,': 1,\n",
       " 'haja': 2,\n",
       " 'barganhas,': 1,\n",
       " 'negociatas': 1,\n",
       " 'argentinizacao': 1,\n",
       " 'querem': 4,\n",
       " 'grande': 5,\n",
       " 'amazon‚Äù': 1,\n",
       " 'rousseff,': 1,\n",
       " 'ops': 1,\n",
       " 'amazonprime': 1,\n",
       " 'qwh': 1,\n",
       " 'zn': 1,\n",
       " 'renovar': 1,\n",
       " 'passaporte': 1,\n",
       " 's√£o': 5,\n",
       " 'euros': 1,\n",
       " 'tenho': 5,\n",
       " 'comprar': 3,\n",
       " 'envelope': 1,\n",
       " 'envio': 5,\n",
       " 'inacredit√°vel': 1,\n",
       " 'üò†': 1,\n",
       " 'faltou': 1,\n",
       " 'nariz': 1,\n",
       " 'palha√ßo': 1,\n",
       " 'ü§°': 1,\n",
       " '@dimacgarcia': 1,\n",
       " 'olavotemraz√£o': 1,\n",
       " 'sempre': 7,\n",
       " 'isso': 8,\n",
       " 'ficam': 1,\n",
       " 'flavio': 1,\n",
       " 'assina': 1,\n",
       " 'cpi': 15,\n",
       " 'lava': 1,\n",
       " 'toga': 1,\n",
       " 'resolvesse': 1,\n",
       " 'lembra': 1,\n",
       " 'ser√°': 1,\n",
       " 'privatizado,': 1,\n",
       " 'tanto': 1,\n",
       " 'roubado': 1,\n",
       " 'povo': 2,\n",
       " 'vive': 1,\n",
       " 'histeria': 1,\n",
       " '@juliannahbatist': 2,\n",
       " 'amaz√¥nia': 2,\n",
       " 'queimando,': 2,\n",
       " 'incidentes': 2,\n",
       " 'diplom√°ticos,': 2,\n",
       " 'subservi√™ncia': 2,\n",
       " 'eua,': 2,\n",
       " '√≠ndices': 2,\n",
       " 'desemprego': 2,\n",
       " 'alta,': 2,\n",
       " 'falta': 4,\n",
       " 'm√©dicos': 2,\n",
       " '(‚Ä¶': 2,\n",
       " '@josromocostafi': 1,\n",
       " 'boa': 3,\n",
       " 'fazer': 7,\n",
       " 'compara√ß√£o': 1,\n",
       " 'com': 20,\n",
       " 'gasolina': 1,\n",
       " 'mas,': 1,\n",
       " 'prop√≥sito,': 1,\n",
       " 'eua': 1,\n",
       " 'postal,': 1,\n",
       " 'sabia': 1,\n",
       " 'usps': 1,\n",
       " 'h√°': 2,\n",
       " 'tamb√©m': 1,\n",
       " 'casos': 1,\n",
       " 'privatiza√ß√µes': 1,\n",
       " 'desastrosas': 1,\n",
       " 'portugal': 1,\n",
       " 'argentina,': 1,\n",
       " 'tiveram': 1,\n",
       " 'revertidas': 1,\n",
       " 'simples': 1,\n",
       " '@beafioroni': 2,\n",
       " '‚Ä¢': 3,\n",
       " 'thread': 2,\n",
       " 'caso': 2,\n",
       " 'luka': 1,\n",
       " 'magnotta': 1,\n",
       " 'ator': 2,\n",
       " 'porn√¥': 2,\n",
       " 'acusado': 1,\n",
       " 'matar,': 1,\n",
       " 'comer,': 1,\n",
       " 'esquartejar': 1,\n",
       " 'enviar': 3,\n",
       " 'partes': 2,\n",
       " 'corpo': 2,\n",
       " 'pelos‚Ä¶': 2,\n",
       " '@ptk': 1,\n",
       " 'renan': 1,\n",
       " '@luuhfelix': 2,\n",
       " 'jaee,': 2,\n",
       " 'espera': 2,\n",
       " 'seguir': 2,\n",
       " 'pelo': 4,\n",
       " 'üôÖüèæ\\u200d‚ôÇÔ∏èüòâ': 2,\n",
       " 'realmente': 2,\n",
       " 'dilma,': 1,\n",
       " 'oremos': 1,\n",
       " 'tornem': 1,\n",
       " 'hahahha': 1,\n",
       " 'co/edm': 1,\n",
       " 'eqk': 1,\n",
       " '@alexpressonauta': 1,\n",
       " 'resto': 2,\n",
       " 'pr√©': 2,\n",
       " 'sal,': 1,\n",
       " 'embraer,': 1,\n",
       " 'petrobras,': 4,\n",
       " 'alc√¢ntara,': 1,\n",
       " 'amaz√¥nia,': 1,\n",
       " 'lula': 1,\n",
       " 'preso': 1,\n",
       " 'essas': 1,\n",
       " 'pautas': 1,\n",
       " 'interessam‚Ä¶': 1,\n",
       " '@deborah': 1,\n",
       " 'gurgeel': 1,\n",
       " 'depende,': 1,\n",
       " 'ela': 5,\n",
       " 'pode': 4,\n",
       " 'mandada': 1,\n",
       " 'qualquer': 2,\n",
       " 'ficar': 2,\n",
       " 'olho': 3,\n",
       " 'onde': 3,\n",
       " 'vai,': 1,\n",
       " 'atrav√©s': 1,\n",
       " 'c√≥digo': 1,\n",
       " 'rastreamento': 3,\n",
       " 'night': 1,\n",
       " 'downtown': 1,\n",
       " 'santoandre': 1,\n",
       " 'noite': 1,\n",
       " 'urbanphotography': 1,\n",
       " 'city': 1,\n",
       " 'p√ßa': 1,\n",
       " 'iv': 1,\n",
       " 'centen√°rio': 1,\n",
       " 'co/ul': 1,\n",
       " 'qtflbeh': 1,\n",
       " 'to': 2,\n",
       " 'levando': 1,\n",
       " 'minha': 4,\n",
       " 'identidade': 1,\n",
       " 'hj': 2,\n",
       " 'passar': 1,\n",
       " 'tomara': 1,\n",
       " 'meus': 1,\n",
       " '√°lbuns': 1,\n",
       " 'j√°': 8,\n",
       " 'tenham': 1,\n",
       " 'chegado': 1,\n",
       " '@queenmychem': 1,\n",
       " 'vou': 4,\n",
       " 'doar,': 1,\n",
       " 'nao': 1,\n",
       " 'tive': 1,\n",
       " 'tempo': 2,\n",
       " 'ir': 2,\n",
       " 'levar': 1,\n",
       " 'nos': 11,\n",
       " '@capitaobrasilll': 1,\n",
       " '@malzonewild': 1,\n",
       " '@arthurweint': 1,\n",
       " '@lindoso': 1,\n",
       " 'stanley': 1,\n",
       " 'da√≠': 1,\n",
       " 'frete': 3,\n",
       " 'custa': 1,\n",
       " 'r': 11,\n",
       " ',': 15,\n",
       " '(que': 1,\n",
       " 'inclusive': 2,\n",
       " 'menor)': 1,\n",
       " 'regi‚Ä¶': 1,\n",
       " '@brasauscolombia': 1,\n",
       " '@aandrade': 2,\n",
       " 'reclamou': 2,\n",
       " 'rsrsrs': 2,\n",
       " '@jpeax': 1,\n",
       " 'produto': 2,\n",
       " 'saiu': 2,\n",
       " 'entrega': 4,\n",
       " 'destinat√°rio': 2,\n",
       " 'co/zvr': 2,\n",
       " 'm': 3,\n",
       " 'srkp': 2,\n",
       " '@mariadorosario': 1,\n",
       " 'audi√™ncia': 1,\n",
       " 'comiss√£o': 1,\n",
       " 'legisla√ß√£o': 1,\n",
       " 'participativa': 1,\n",
       " 'realizamos': 1,\n",
       " 'parceria': 1,\n",
       " 'assembleia': 4,\n",
       " 'rs': 2,\n",
       " 'r‚Ä¶': 1,\n",
       " 'esquerdopata': 1,\n",
       " 'acha': 1,\n",
       " 'ruim': 1,\n",
       " 'üëäüí™': 1,\n",
       " 'privatizatudo': 1,\n",
       " 'co/pmm': 1,\n",
       " 'z': 1,\n",
       " 'zo': 1,\n",
       " '@homefilatelista': 1,\n",
       " 'imagem': 2,\n",
       " 'destacada': 2,\n",
       " 'vemos': 2,\n",
       " 'silhueta': 2,\n",
       " 'cabe√ßa': 2,\n",
       " 'cont√©m': 2,\n",
       " 'muitos': 4,\n",
       " 'outras': 5,\n",
       " 'trata': 2,\n",
       " 'alegoria': 2,\n",
       " 'utilizada': 2,\n",
       " 'gerente': 3,\n",
       " 'sal√°rio': 3,\n",
       " 'benef√≠cios': 3,\n",
       " 'sa√∫de': 4,\n",
       " 'vt': 3,\n",
       " 'local': 3,\n",
       " 'bh': 3,\n",
       " 'hor√°rio': 3,\n",
       " 'segunda': 3,\n",
       " '√°': 3,\n",
       " 'sexta‚Äì': 1,\n",
       " 'feira': 2,\n",
       " 'horas': 2,\n",
       " '√°s': 1,\n",
       " 'atividades': 1,\n",
       " 'gest√£o': 1,\n",
       " 'ag√™ncia,': 1,\n",
       " 'vendas': 1,\n",
       " 'equipe': 1,\n",
       " 'co/fngjxvgfdm': 1,\n",
       " '@epicastpodcast': 1,\n",
       " 'chegou': 1,\n",
       " 'gr√°fica': 1,\n",
       " 'agora,': 1,\n",
       " 'l√°': 3,\n",
       " 'autografar': 1,\n",
       " 'final': 1,\n",
       " 'nada': 3,\n",
       " 'nunca': 3,\n",
       " 'mudar': 2,\n",
       " 'entre': 3,\n",
       " 'nossa': 2,\n",
       " 'amizade': 1,\n",
       " 'importa': 1,\n",
       " 'aconte√ßa': 1,\n",
       " '(e': 2,\n",
       " 'olha': 1,\n",
       " 'tivemos': 1,\n",
       " 'provas': 1,\n",
       " 'vivas': 1,\n",
       " 'disso': 1,\n",
       " 'kkkk)': 1,\n",
       " 'te': 1,\n",
       " 'amo': 1,\n",
       " 'meu': 5,\n",
       " 'amor,': 1,\n",
       " 'prefira': 1,\n",
       " 'modo': 1,\n",
       " 'noturno': 1,\n",
       " '@jjkscore': 1,\n",
       " 'consigo': 3,\n",
       " 'ver': 5,\n",
       " 'triste': 2,\n",
       " 'tl': 2,\n",
       " 'velho,': 2,\n",
       " 'tentar': 3,\n",
       " 'ajudar,': 2,\n",
       " 't√¥': 3,\n",
       " 'mandando': 2,\n",
       " 'an√¥nim‚Ä¶': 1,\n",
       " 'caraleo': 1,\n",
       " 'viu': 1,\n",
       " 'co/oeceiwqdia': 1,\n",
       " 'suspeitos': 1,\n",
       " 'assaltar': 1,\n",
       " 'presos': 1,\n",
       " 'serrana': 1,\n",
       " 'co/bnjnzc': 1,\n",
       " 'g': 1,\n",
       " 'n': 5,\n",
       " '@jaoike': 1,\n",
       " '@clubemondoverde': 1,\n",
       " 'perto': 1,\n",
       " 'antes': 2,\n",
       " 'bradesco': 1,\n",
       " 'pagamento': 3,\n",
       " 'transfer√™ncia': 1,\n",
       " 'banc√°ria': 1,\n",
       " 'posso': 2,\n",
       " 'negociar': 1,\n",
       " 'formas': 1,\n",
       " 'reservo': 1,\n",
       " 'm√°ximo': 2,\n",
       " 'dias,': 1,\n",
       " 'vez': 1,\n",
       " 'mando': 1,\n",
       " 'dias': 2,\n",
       " '√∫teis': 1,\n",
       " 'ap√≥s': 2,\n",
       " 'cair': 1,\n",
       " '(demora': 1,\n",
       " 'm√©dia': 1,\n",
       " 'semana': 1,\n",
       " 'chegar)': 1,\n",
       " 'd√∫vidas': 1,\n",
       " 'demais': 1,\n",
       " 'informa√ß√µes,': 1,\n",
       " 'dm': 1,\n",
       " '@cwamilapower': 1,\n",
       " '+': 2,\n",
       " 'imprimir': 1,\n",
       " 'poder': 1,\n",
       " 'despachar': 1,\n",
       " 'basicamente': 1,\n",
       " 'isso,': 2,\n",
       " 'tiver': 1,\n",
       " 'alguma': 1,\n",
       " 'd√∫vida': 1,\n",
       " 'chamar': 1,\n",
       " '@bhcbdv': 2,\n",
       " 'sext‚Ä¶': 2,\n",
       " 'üñáfrom': 1,\n",
       " 'an√¥nimo': 1,\n",
       " 'üñáto': 1,\n",
       " '@taelitw': 1,\n",
       " 'palavras': 1,\n",
       " 'seriam': 1,\n",
       " 'capazes': 1,\n",
       " 'expressar': 1,\n",
       " 'amor': 1,\n",
       " 'sinto': 1,\n",
       " 'ti,': 1,\n",
       " 'durante': 1,\n",
       " 'anos': 2,\n",
       " 'perguntando': 1,\n",
       " 'valeria': 1,\n",
       " 'pena': 1,\n",
       " 'talvez': 2,\n",
       " 'tenha': 2,\n",
       " 'certeza': 1,\n",
       " 'espero': 2,\n",
       " 'importe': 1,\n",
       " 'qu√£o': 1,\n",
       " 'melosa': 1,\n",
       " 'vezes': 1,\n",
       " 'quero': 1,\n",
       " '@mercadolivre': 1,\n",
       " 'endere√ßo': 1,\n",
       " 'entrega,': 1,\n",
       " 'pegar': 1,\n",
       " 'compra': 3,\n",
       " 'algum': 1,\n",
       " 'lugar': 2,\n",
       " 'dar': 1,\n",
       " 'jeito': 2,\n",
       " 'entrar': 1,\n",
       " 'contato': 2,\n",
       " 'atual': 2,\n",
       " 'morador': 1,\n",
       " 'resid√™ncia': 1,\n",
       " 'agrade√ßo': 1,\n",
       " 'ajuda': 1,\n",
       " '^^': 1,\n",
       " '@reggianidavi': 1,\n",
       " 'erro': 1,\n",
       " 'cidad√£o': 2,\n",
       " 'atualizando': 1,\n",
       " 'toda': 2,\n",
       " 'hora': 3,\n",
       " 'fico': 1,\n",
       " 'morrer': 1,\n",
       " 'estou': 1,\n",
       " 'esperando': 4,\n",
       " 'queria': 1,\n",
       " 'receber': 1,\n",
       " 'an√¥nimos': 2,\n",
       " '@pestenegrapcst': 1,\n",
       " 'porra,ta': 1,\n",
       " 'meses': 1,\n",
       " 'liminar,ta': 1,\n",
       " 'vindo': 2,\n",
       " 'via': 1,\n",
       " 'sa': 1,\n",
       " 'porra': 2,\n",
       " 'vire': 1,\n",
       " 'prime': 4,\n",
       " 'conte√∫do': 1,\n",
       " 'infinito': 1,\n",
       " 'coisinhas': 1,\n",
       " 'escrevo': 1,\n",
       " 'conversando': 1,\n",
       " 'tweets': 1,\n",
       " '@daircarvalho': 1,\n",
       " 'mundo,': 1,\n",
       " 'principalmente': 1,\n",
       " 'mo√ßo': 1,\n",
       " '/': 2,\n",
       " 'trabalhadores': 2,\n",
       " 'co/y': 1,\n",
       " 'mdnkjaim': 1,\n",
       " 'opa': 1,\n",
       " 'poderia': 1,\n",
       " 'porfavor': 1,\n",
       " 'co/fuqxckylvb': 1,\n",
       " 'necessidade': 1,\n",
       " 'eletrobras': 3,\n",
       " 'sequer': 1,\n",
       " 'muitas': 1,\n",
       " 'ag√™ncias': 2,\n",
       " 'banc√°rias': 1,\n",
       " 'acordem': 1,\n",
       " '@leandro': 1,\n",
       " 'jcampos': 1,\n",
       " '@folha': 2,\n",
       " 'sim': 1,\n",
       " 'cara,': 1,\n",
       " 'entendo': 3,\n",
       " 'rentabilidade': 1,\n",
       " 'trabalhei': 1,\n",
       " 'log√≠stica': 1,\n",
       " 'opera√ß√£o': 1,\n",
       " 'bato': 1,\n",
       " 'tecla': 1,\n",
       " 'monop√≥lio,': 2,\n",
       " 'tema': 1,\n",
       " 'pr√≥pria': 2,\n",
       " 'faz': 1,\n",
       " 'ficando': 1,\n",
       " 'claro': 1,\n",
       " 'interesse': 3,\n",
       " '@senhormauricio': 1,\n",
       " '@sergiorevere': 1,\n",
       " '@lolaescreva': 1,\n",
       " '@haddad': 1,\n",
       " 'fernando': 1,\n",
       " 'engra√ßado': 1,\n",
       " 'petista': 1,\n",
       " 'pedindo': 1,\n",
       " 'prova': 1,\n",
       " 'esqueceram': 1,\n",
       " 'oas,': 1,\n",
       " 'odebrecht,': 1,\n",
       " 'dela√ß√£o': 1,\n",
       " 'palocci': 1,\n",
       " 'maracutaias': 1,\n",
       " 'comprovadas': 1,\n",
       " 'culpado': 1,\n",
       " 'queiroz,': 1,\n",
       " 'deve': 2,\n",
       " 'sido': 1,\n",
       " 'desviou': 1,\n",
       " 'grana': 1,\n",
       " '@ivannescaa': 1,\n",
       " '@bethguimares': 1,\n",
       " 'carece': 1,\n",
       " 'digre√ß√£o': 1,\n",
       " 'basta': 1,\n",
       " 'olhar': 1,\n",
       " 'funcion√°rios': 3,\n",
       " 'gritando': 1,\n",
       " 'privatiza': 1,\n",
       " '@nathansg': 1,\n",
       " 'cuidaram': 1,\n",
       " 'muito': 2,\n",
       " 'dele': 1,\n",
       " 'tempo,': 1,\n",
       " 'aposto': 1,\n",
       " 'greve': 4,\n",
       " 'tocantins,': 1,\n",
       " 'marcada': 1,\n",
       " 'pr√≥xima': 1,\n",
       " 'quarta': 2,\n",
       " 'co/x': 1,\n",
       " 'apviatbz': 1,\n",
       " '@nesleykent': 1,\n",
       " 'cade': 2,\n",
       " '@dilmabr': 2,\n",
       " 'precisamos': 2,\n",
       " 'agora': 2,\n",
       " 'vida': 3,\n",
       " '@heldercervantes': 1,\n",
       " '@typisktugisk': 1,\n",
       " 'prenderam': 1,\n",
       " 'marco': 1,\n",
       " '@o': 1,\n",
       " 'antagonista': 1,\n",
       " 'pior': 1,\n",
       " 'roubar': 1,\n",
       " 'petrobras': 1,\n",
       " 'inocente': 1,\n",
       " '@emrcanelas': 1,\n",
       " '@herminiocerq': 2,\n",
       " '@cristasassuncao': 2,\n",
       " 'nacionalizar': 1,\n",
       " 'defende': 1,\n",
       " 'das': 3,\n",
       " 'duas': 1,\n",
       " 'demagogia': 1,\n",
       " 'enganar': 1,\n",
       " 'tolos': 1,\n",
       " 'problema': 2,\n",
       " 'mental': 1,\n",
       " 'grave': 1,\n",
       " '@uolnoticias': 1,\n",
       " 'bozo': 2,\n",
       " 't√°': 5,\n",
       " 'fazendo': 2,\n",
       " 'destru√≠': 1,\n",
       " 'brasileiro,ele': 1,\n",
       " 'mede': 1,\n",
       " 'esfosso': 1,\n",
       " 'redu√ß√£o': 1,\n",
       " 'verbas': 1,\n",
       " 'educa√ß√£o,agora': 1,\n",
       " 'canalha': 2,\n",
       " 'igual': 1,\n",
       " '@sansadu': 1,\n",
       " '@herculanofagu': 1,\n",
       " '@allantercalivre': 1,\n",
       " 'levou': 2,\n",
       " 'cassa√ß√£o': 1,\n",
       " 'mandato': 1,\n",
       " 'collor': 1,\n",
       " 'processos': 1,\n",
       " 'iniciaram': 1,\n",
       " 'mensal√£o': 4,\n",
       " 'aprendiz': 1,\n",
       " 'sem': 6,\n",
       " 'co/i': 1,\n",
       " 'sll': 1,\n",
       " 'kmzv': 1,\n",
       " '@iaragb': 5,\n",
       " 'resultado': 5,\n",
       " 'indiciou': 5,\n",
       " 'pessoas,': 5,\n",
       " 'fez': 6,\n",
       " 'propostas': 5,\n",
       " 'aumento': 5,\n",
       " 'rigor': 5,\n",
       " 'aplica√ß√£o': 5,\n",
       " 'verbas‚Ä¶': 5,\n",
       " 'haver√°': 2,\n",
       " 'atender': 2,\n",
       " 'todos,': 2,\n",
       " 'diz': 2,\n",
       " 'ex': 2,\n",
       " 'funcion√°rio': 3,\n",
       " 'co/duzyf': 1,\n",
       " 'td': 1,\n",
       " 'f': 1,\n",
       " 'virar': 1,\n",
       " 'co/j': 1,\n",
       " 'hqcrei': 1,\n",
       " 't': 1,\n",
       " 'amea√ßados': 1,\n",
       " 'defend√™': 1,\n",
       " 'los': 1,\n",
       " 'co/q': 1,\n",
       " 'gwegzpvl': 1,\n",
       " 'fui': 2,\n",
       " 'tia,': 1,\n",
       " 'adriel,': 1,\n",
       " 'adriele': 1,\n",
       " 'jogar': 1,\n",
       " 'esteio': 1,\n",
       " 'agr': 1,\n",
       " 'canoas': 1,\n",
       " 'ronaldinho': 1,\n",
       " 'ia': 1,\n",
       " 'sentir': 2,\n",
       " 'orgulho': 1,\n",
       " 'desses': 2,\n",
       " 'rol√™': 1,\n",
       " 'aleat√≥rio': 1,\n",
       " '@emrsnf': 1,\n",
       " 'br': 3,\n",
       " '@prefeituradegyn': 1,\n",
       " '‚ö†': 1,\n",
       " 'garantiu': 1,\n",
       " 'cpf': 1,\n",
       " 'filho': 1,\n",
       " 'documento': 2,\n",
       " 'obrigat√≥rio': 1,\n",
       " 'realizar': 1,\n",
       " 'matr√≠cula': 1,\n",
       " 'escolas': 1,\n",
       " 'cmeis': 1,\n",
       " 'de‚Ä¶': 2,\n",
       " '@intoyurik': 1,\n",
       " 'abre': 2,\n",
       " 'concurso': 2,\n",
       " 'escolha': 2,\n",
       " 'selo': 3,\n",
       " 'natal': 2,\n",
       " 'co/z': 1,\n",
       " 'azmw': 1,\n",
       " 'aac': 1,\n",
       " 'conmebol': 1,\n",
       " 'fizer': 1,\n",
       " 'novo': 1,\n",
       " 'aquele': 2,\n",
       " 'far': 1,\n",
       " 'play': 1,\n",
       " 'semifinalistas,': 1,\n",
       " 'seria': 1,\n",
       " 'romildo': 1,\n",
       " 'assinar,': 1,\n",
       " 'esfregar': 1,\n",
       " 'saco': 1,\n",
       " 'mandar': 2,\n",
       " 'volta': 1,\n",
       " 'sei': 1,\n",
       " '@siqueirambl': 3,\n",
       " 'vereador': 4,\n",
       " 'cidade': 5,\n",
       " 'rio': 4,\n",
       " 'janeiro,': 4,\n",
       " '@carlosbolsonaro': 5,\n",
       " 'pediu': 4,\n",
       " 'licen√ßa': 4,\n",
       " 'remunera√ß√£o': 4,\n",
       " 'cargo': 4,\n",
       " 'vamos': 4,\n",
       " 'since‚Ä¶': 3,\n",
       " 'üî•hot': 1,\n",
       " 'takeüî•': 1,\n",
       " 'lan√ßou': 1,\n",
       " 'evitar': 1,\n",
       " 'profecia': 1,\n",
       " \"'correios\": 1,\n",
       " 'tornarem': 1,\n",
       " \"amazon'\": 1,\n",
       " 'concretize': 1,\n",
       " 'b√©lgica': 1,\n",
       " 'falar': 2,\n",
       " 'diferen√ßas': 1,\n",
       " 'seres': 1,\n",
       " 'humanos': 1,\n",
       " 'seja': 1,\n",
       " 'for': 1,\n",
       " 'apar√™ncia': 1,\n",
       " 'somos': 1,\n",
       " 'iguais': 1,\n",
       " 'b': 1,\n",
       " 'co/xrgm': 1,\n",
       " 'otqy': 1,\n",
       " 'jm': 1,\n",
       " 'grf': 1,\n",
       " '@silasvrb': 1,\n",
       " 'estadia': 1,\n",
       " 'horror': 1,\n",
       " 'deus': 2,\n",
       " 'co/xjjal': 1,\n",
       " 'ho': 1,\n",
       " 'mesmo,': 1,\n",
       " 'foda': 2,\n",
       " 'demaaaais': 1,\n",
       " 'vende': 2,\n",
       " 'logo': 1,\n",
       " 't√£o': 2,\n",
       " 'co/eyc': 1,\n",
       " 'yu': 1,\n",
       " 'aw': 1,\n",
       " 'privatizarem': 1,\n",
       " 'valer': 1,\n",
       " 'menos': 2,\n",
       " 'co/s': 1,\n",
       " 'bcr': 1,\n",
       " 'djxc': 1,\n",
       " '=': 2,\n",
       " 'co/vktba': 2,\n",
       " 'qz': 2,\n",
       " '@leandroruschel': 1,\n",
       " 'esquerd‚Ä¶': 1,\n",
       " 'merda': 4,\n",
       " 'concordo': 1,\n",
       " 'essa': 3,\n",
       " 'precisa': 1,\n",
       " 'privatizada': 1,\n",
       " 'brasil,': 1,\n",
       " 'entreguista': 1,\n",
       " 'fascista': 1,\n",
       " '@clarissadelune': 1,\n",
       " 'a√≠': 1,\n",
       " 'resposta': 1,\n",
       " 'f√°cil,': 1,\n",
       " 'parece': 1,\n",
       " 'come√ßo': 1,\n",
       " 'jeito,': 1,\n",
       " 'criar': 1,\n",
       " 'demanda': 1,\n",
       " 'aquela': 2,\n",
       " 'localidade': 1,\n",
       " 'torne': 1,\n",
       " 'atrativa': 1,\n",
       " 'iniciativa': 1,\n",
       " 'privada': 2,\n",
       " 'tendo': 1,\n",
       " 'demanda,': 1,\n",
       " 'poderiam': 1,\n",
       " 'aproveitar': 1,\n",
       " 'centros': 1,\n",
       " 'distribui√ß√£o': 1,\n",
       " 'correios+': 1,\n",
       " '@correios': 2,\n",
       " 'anon': 2,\n",
       " '@jiminseason': 1,\n",
       " 'mande': 1,\n",
       " 'mimos': 1,\n",
       " 'üòîüòîüòîüëçüëçüëçüëç': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cria database setarada de relevantes e irrelevantes\n",
    "data_frame_rlevantes = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==1]\n",
    "serie_relevantes=pd.Series(data_frame_rlevantes[\"Treinamento\"])\n",
    "data_frame_nao_rlevantes = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==0]\n",
    "serie_nao_relevantes=pd.Series(data_frame_nao_rlevantes[\"Treinamento\"])\n",
    "#conta a incidencia de cada palavra\n",
    "contagem_relevantes={}\n",
    "for T in serie_relevantes:\n",
    "    contagem_relevantes=conta_palavra(T,contagem_relevantes)\n",
    "contagem_nao_relevantes={}\n",
    "for T in serie_nao_relevantes:\n",
    "    serie_nao_relevantes=conta_palavra(T,contagem_nao_relevantes)\n",
    "\n",
    "#associa um valor de probabilidade\n",
    "probrev={}\n",
    "\n",
    "#formato {palavra:valor}\n",
    "probnorev={}\n",
    "#formato {palavra:valor}\n",
    "serie_nao_relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoth = 1/1000000 #√© uma estimativa e deve mudar\n",
    "# defini probabilidade de ser relevante:\n",
    "def relevante(tweet):\n",
    "    t = clean(tweet)\n",
    "    prob = 1\n",
    "    for p in t:\n",
    "        if p in probrev:\n",
    "            prob = prob*(probrev(p)+smoth)\n",
    "        else:\n",
    "            prob = prob*(smoth)\n",
    "    prob = prev\n",
    "# defini probabilidade de ser irrelevante:\n",
    "def relevante(tweet):\n",
    "    t = clean(tweet)\n",
    "    prob = 1\n",
    "    for p in t:\n",
    "        if p in probnorev:\n",
    "            prob = prob*(probnorev(p)+smoth)\n",
    "        else:\n",
    "            prob = prob*(smoth)\n",
    "    prob = pnorev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara (tweet):\n",
    "    r = relevante(tweet)\n",
    "    nor = irrelevante(tweet)\n",
    "    return r>nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-87-590e40ef14d4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-87-590e40ef14d4>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    arquivo =\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "arquivo = \n",
    "rev = 0\n",
    "norev = 0\n",
    "for txt in arquivo:\n",
    "    if compara (txt):\n",
    "        rev +=1\n",
    "    else:\n",
    "        norev+=1\n",
    "print (\"a probabilidade de ser relevante √© {}\".format(rev/arquivo.len()))\n",
    "print (\"a probabilidade de n√£o ser relevante √© {}\".format(rev/arquivo.len()))\n",
    "if rev/arquivo.len() < 0.9*prev:\n",
    "    print (\"poucos relevantes\")\n",
    "elif rev/arquivo.len() > 1.1*prev:\n",
    "    print (\"muitos relevantes\")\n",
    "else:\n",
    "    print (\"ok: {} veze o esperado\".format (rev/arquivo.len()/prev))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
