{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nome: Bruno Meneghesso da Silva\n",
    "\n",
    "Nome: Diogo Nobre de Araujo Cintra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento para o Twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy\n",
    "%matplotlib inline\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange\n",
    "from numpy import percentile\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autenticando aconta do Twitter\n",
    "\n",
    "#### Conta: @Ciencia dos dados"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coletando os dados do Twitter:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Correios'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'\n",
    "\n",
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação dos tweets\n",
    "#### 0 = irrelevante\n",
    "#### 1 = relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abrindo a planilha do Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREINAMENTO = pd.read_excel('Correios.xlsx',sheet_name = 'Treinamento')\n",
    "TESTE = pd.read_excel('Correios.xlsx',sheet_name = 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrando base de treinamento em relevante e irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREINAMENTO_RELEVANTE = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==1]\n",
    "TREINAMENTO_IRRELEVANTE = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para limpar a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    punctuation = '[!\\-.:?;#$%&*_1234567890\"]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando a função e limpando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_relevante = \" \".join(TREINAMENTO_RELEVANTE['Treinamento'])\n",
    "texto_relevante_1 = clean(texto_relevante)\n",
    "texto_relevante_2 = texto_relevante_1.split()\n",
    "texto_relevante_3 = []\n",
    "\n",
    "texto_irrelevante = \" \".join(TREINAMENTO_IRRELEVANTE['Treinamento'])\n",
    "texto_irrelevante_1 = clean(texto_irrelevante)\n",
    "texto_irrelevante_2 = texto_irrelevante_1.split()\n",
    "texto_irrelevante_3 = []\n",
    "\n",
    "treinamento = \" \".join(TREINAMENTO['Treinamento'])\n",
    "treinamento_1 = clean(treinamento)\n",
    "treinamento_2 = treinamento_1.split()\n",
    "treinamento_3 = []\n",
    "\n",
    "teste = \" \".join(TESTE['Teste'])\n",
    "teste_1 = clean(teste)\n",
    "teste_2 = teste_1.split()\n",
    "teste_3 = []\n",
    "\n",
    "for e in range(len(texto_relevante_2)-1):\n",
    "    if texto_relevante_2[e] != 'rt' and texto_relevante_2[e][0] != '@':     \n",
    "        texto_relevante_3.append(texto_relevante_2[e])    \n",
    "        \n",
    "for e in range(len(texto_irrelevante_2)-1):\n",
    "    if texto_irrelevante_2[e] != 'rt' and texto_irrelevante_2[e][0] != '@':     \n",
    "        texto_irrelevante_3.append(texto_irrelevante_2[e]) \n",
    "        \n",
    "for e in range(len(treinamento_2)-1):\n",
    "    if treinamento_2[e] != 'rt' and treinamento_2[e][0] != '@':     \n",
    "        treinamento_3.append(treinamento_2[e])\n",
    "        \n",
    "for e in range(len(teste_2)-1):\n",
    "    if teste_2[e] != 'rt' and teste_2[e][0] != '@':     \n",
    "        teste_3.append(teste_2[e])        \n",
    "        \n",
    "texto_relevante_4 = pd.Series(texto_relevante_3)\n",
    "texto_irrelevante_4 = pd.Series(texto_irrelevante_3)\n",
    "treinamento_4 = pd.Series(treinamento_3)\n",
    "teste_4 = pd.Series(teste_3)\n",
    "\n",
    "total_amostral_teste = len(teste_4)\n",
    "total_amostral_treinamento = len(treinamento_4)\n",
    "total_relevante = texto_relevante_4.value_counts()\n",
    "total_irrelevante = texto_irrelevante_4.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade do tweet ser relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de um tweet ser relevante: 40.13%\n"
     ]
    }
   ],
   "source": [
    "prob_relevante = len(TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==1])/len(TREINAMENTO[\"Treinamento\"])\n",
    "print(\"Probabilidade de um tweet ser relevante: {:.2f}%\".format(prob_relevante*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade do tweet ser relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de um tweet ser relevante: 59.87%\n"
     ]
    }
   ],
   "source": [
    "prob_irrelevante = len(TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==0])/len(TREINAMENTO[\"Treinamento\"])\n",
    "print(\"Probabilidade de um tweet ser relevante: {:.2f}%\".format(prob_irrelevante*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de uma palavra ser relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_relevante_palavra = total_relevante/total_amostral_treinamento\n",
    "#print(\"Probabilidade de cada palavra ser relevante\")\n",
    "#print(prob_relevante_palavra*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de uma palavra ser irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_irrelevante_palavra = total_irrelevante/total_amostral_treinamento\n",
    "#print(\"Probabilidade de cada palavra ser irrelevante\")\n",
    "#print(prob_irrelevante_palavra*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções para o cálculo da probabilidade de ser relevante e irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_relevante_teste = len(TESTE.loc[TESTE[\"Classificacao\"]==1])/len(TESTE[\"Teste\"])\n",
    "prob_irrelevante_teste = len(TESTE.loc[TESTE[\"Classificacao\"]==0])/len(TESTE[\"Teste\"])\n",
    "\n",
    "smoth = 1e-10 #é uma estimativa e deve mudar\n",
    "vocabulario = 356000\n",
    "\n",
    "# defini probabilidade de ser relevante:\n",
    "def relevante(tweet):\n",
    "    \n",
    "    tweet_relevante_2 = clean(tweet)\n",
    "    tweet_relevante_3 = tweet_relevante_2.split()\n",
    "    tweet_relevante_4 = []\n",
    "    \n",
    "    for e in range(len(tweet_relevante_3)-1):\n",
    "        \n",
    "        if tweet_relevante_3[e] != 'rt' and tweet_relevante_3[e][0] != '@':     \n",
    "            tweet_relevante_4.append(tweet_relevante_3[e])\n",
    "            \n",
    "    prob = 1\n",
    "    \n",
    "    for p in tweet_relevante_4:\n",
    "        \n",
    "        if p in prob_relevante_palavra:\n",
    "            prob = prob*(prob_relevante_palavra[p]*total_relevante.size+smoth)/(total_relevante.size+smoth*vocabulario)*1000\n",
    "        else:\n",
    "            prob = prob*(smoth)/(total_relevante.size+smoth*vocabulario)*1000\n",
    "            \n",
    "    prob = prob * prob_relevante\n",
    "    prob = math.log10(prob)\n",
    "    return prob\n",
    "\n",
    "# defini probabilidade de ser irrelevante:\n",
    "def irrelevante(tweet):\n",
    "    \n",
    "    tweet_irrelevante_2 = clean(tweet)\n",
    "    tweet_irrelevante_3 = tweet_irrelevante_2.split()\n",
    "    tweet_irrelevante_4 = []\n",
    "    \n",
    "    for e in range(len(tweet_irrelevante_3)-1):\n",
    "        \n",
    "        if tweet_irrelevante_3[e] != 'rt' and tweet_irrelevante_3[e][0] != '@':     \n",
    "            tweet_irrelevante_4.append(tweet_irrelevante_3[e])\n",
    "            \n",
    "    prob = 1\n",
    "    \n",
    "    for p in tweet_irrelevante_4:\n",
    "        \n",
    "        if p in prob_irrelevante_palavra:\n",
    "            prob = prob*(prob_irrelevante_palavra[p]*total_irrelevante.size+smoth)/(total_irrelevante.size+smoth*vocabulario)*1000\n",
    "        else:\n",
    "            prob = prob*(smoth)/(total_irrelevante.size+smoth*vocabulario)*1000\n",
    "            \n",
    "    prob = prob * prob_irrelevante\n",
    "    prob = math.log10(prob)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando a performance do algoritmo com a base de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara (tweet):\n",
    "    \n",
    "    r = relevante(tweet)\n",
    "    nor = irrelevante(tweet)\n",
    "    \n",
    "    return r>nor\n",
    "\n",
    "rev = 0\n",
    "norev = 0\n",
    "\n",
    "#rev = Relevante\n",
    "#norev = Irrelevante\n",
    "\n",
    "relevantes_algoritimo = []\n",
    "\n",
    "for e in TESTE[\"Teste\"]:\n",
    "    \n",
    "    if compara(e):\n",
    "        rev +=1\n",
    "        relevantes_algoritimo.append(1)\n",
    "    else:\n",
    "        norev+=1\n",
    "        relevantes_algoritimo.append(0)\n",
    "        \n",
    "VP = 0 #Verdadeiros Positivos\n",
    "FP = 0 #Falsos Positivos\n",
    "VN = 0 #Verdadeiros Negativos\n",
    "FN = 0 #Falsos Negativos\n",
    "\n",
    "for n in range (len(relevantes_algoritimo)-1):\n",
    "    \n",
    "    if TESTE[\"Classificacao\"][n] == relevantes_algoritimo[n]:\n",
    "        if relevantes_algoritimo[n] == 1:\n",
    "            VP+=1\n",
    "        else:\n",
    "            FP+=1\n",
    "    else:\n",
    "        if relevantes_algoritimo[n] == 1:\n",
    "            VN+=1\n",
    "        else:\n",
    "            FN+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados do algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de ser relevante segundo o algoritmo: 28.50%\n",
      "Probabilidade de ser irrelevante segundo o algoritmo: 71.50%\n",
      "Probabilidade de ser relevante pela nossa classificação: 44.50%\n",
      "Probabilidade de ser irrelevante pela nossa classificação: 55.50%\n",
      "\n",
      "Porcentagem de Verdadeiros Positivos: 18.50%\n",
      "Porcentagem de Falsos Positivos: 45.50%\n",
      "Porcentagem de Verdadeiros Negativos: 10.00%\n",
      "Porcentagem de Falsos Negativos: 25.50%\n",
      "\n",
      "Acurácia do algoritmo: 64.04%\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidade de ser relevante segundo o algoritmo: {:.2f}%\".format((rev/TESTE[\"Teste\"].size)*100))\n",
    "print(\"Probabilidade de ser irrelevante segundo o algoritmo: {:.2f}%\".format((norev/TESTE[\"Teste\"].size)*100))\n",
    "print(\"Probabilidade de ser relevante pela nossa classificação: {:.2f}%\".format(prob_relevante_teste*100))\n",
    "print(\"Probabilidade de ser irrelevante pela nossa classificação: {:.2f}%\".format(prob_irrelevante_teste*100))\n",
    "print(\"\")\n",
    "print(\"Porcentagem de Verdadeiros Positivos: {:.2f}%\".format(VP/TESTE[\"Classificacao\"].size*100))\n",
    "print(\"Porcentagem de Falsos Positivos: {:.2f}%\".format(FP/TESTE[\"Classificacao\"].size*100))\n",
    "print(\"Porcentagem de Verdadeiros Negativos: {:.2f}%\".format(VN/TESTE[\"Classificacao\"].size*100))\n",
    "print(\"Porcentagem de Falsos Negativos: {:.2f}%\".format(FN/TESTE[\"Classificacao\"].size*100))\n",
    "print(\"\")\n",
    "print(\"Acurácia do algoritmo: {:.2f}%\".format((rev/TESTE[\"Teste\"].size/prob_relevante_teste)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Conclusão\n",
    "#### Validação da acurácia | Com o auxílio do Professor Fábio José Ayres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do resultado segundo a biblioteca: 64.50%\n"
     ]
    }
   ],
   "source": [
    "Xt = TREINAMENTO['Treinamento']\n",
    "y = TREINAMENTO['Classificacao']\n",
    "\n",
    "cnt = CountVectorizer()\n",
    "X = cnt.fit_transform(Xt)\n",
    "nb = MultinomialNB(alpha=1e-10)\n",
    "nb.fit(X, y)\n",
    "\n",
    "Xt_test = TESTE['Teste']\n",
    "y_test = TESTE['Classificacao']\n",
    "\n",
    "X_test = cnt.transform(Xt_test)\n",
    "ypred = nb.predict(X_test)\n",
    "\n",
    "acuracia_biblioteca = accuracy_score(y_test, ypred)*100\n",
    "\n",
    "print(\"Acurácia do resultado segundo a biblioteca: {:.2f}%\".format(acuracia_biblioteca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia do algoritmo desenvolvido pelos integrantes do grupo, foi de 64.04% com o valor do *smoth* de 1e-10. Para validar a acurácia encontrada, com a ajuda do professor Fábio José Ayres, foi utilizado recursos das bibliotecas “sklearn.feature_extraction.text”, “sklearn.naive_bayes” e “sklearn.metrics” para encontrar o valor da acurácia de um algoritmo presente nas bibliotecas que utilizam o classificador de Naive-Bayes. O código acima calcula o valor da acurácia utilizando os recursos das bibliotecas já mencionadas, o valor obtido foi de uma acurácia igual a 64.50%. Dessa forma conclui-se que o algoritmo desenvolvido obteve resultados acima do esperado, com apenas uma diferença para menos da acurácia de 0.46%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Aperfeiçoamento:\n",
    "\n",
    "Para melhorar a acurácia do algoritmo, deveríamos ter três bases de dados: Treinamento, Teste, Controle. Dessa forma iriamos treinar o algoritmo com a base de treinamento, depois testar com a base de teste e variar o valor do *smoth* até que a acurácia do algoritmo seja a melhor possível. Após achar o valor do *smoth* com a base de teste, aplicaríamos o algoritmo na base de controle, observando o valor da acurácia.\n",
    "\n",
    "Além disso a probabilidade base d um tweet ser relevante poderia ser alterada com o intuito de melhorar a acuracia, evitando que relevantes sejam considerados irrelevantes, porém, com os recursos hoje possuidos pelos aunos não é possivel argumentar para um determinado ajuste. O unico método possivel seria manipular diretamente o valor e reiterar com ele para atingir o valor desejado, atitude que não seria condizente com a intenção da atividade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  \n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
